{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### After run this cell, Reboot the kerenl and run the cells below this"
      ],
      "metadata": {
        "id": "BSkDycf68x3E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lIYdn1woOS1n",
        "outputId": "f9721733-94d0-4ded-a4b2-3b61ec93a62c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting finetune\n",
            "  Downloading finetune-0.9.0.tar.gz (850 kB)\n",
            "\u001b[K     |████████████████████████████████| 850 kB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from finetune) (1.3.5)\n",
            "Requirement already satisfied: tqdm>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from finetune) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.18.4 in /usr/local/lib/python3.7/dist-packages (from finetune) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from finetune) (1.7.3)\n",
            "Collecting scikit-learn<0.23,>=0.20.2\n",
            "  Downloading scikit_learn-0.22.2.post1-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1 MB 54.8 MB/s \n",
            "\u001b[?25hCollecting ftfy>=4.4.0\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.2 MB/s \n",
            "\u001b[?25hCollecting spacy<3.0.0,>=2.0.0\n",
            "  Downloading spacy-2.3.7-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4 MB 50.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from finetune) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.12.0 in /usr/local/lib/python3.7/dist-packages (from finetune) (1.1.0)\n",
            "Requirement already satisfied: bs4>=0.0.1 in /usr/local/lib/python3.7/dist-packages (from finetune) (0.0.1)\n",
            "Collecting imbalanced-learn<0.7.0,>=0.6.0\n",
            "  Downloading imbalanced_learn-0.6.2-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 71.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk>=3.2.4 in /usr/local/lib/python3.7/dist-packages (from finetune) (3.7)\n",
            "Requirement already satisfied: regex>=2019.03.12 in /usr/local/lib/python3.7/dist-packages (from finetune) (2022.6.2)\n",
            "Requirement already satisfied: lxml>=4.3.3 in /usr/local/lib/python3.7/dist-packages (from finetune) (4.9.1)\n",
            "Collecting sentencepiece>=0.1.83\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 63.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate<0.9.0,>=0.8.6 in /usr/local/lib/python3.7/dist-packages (from finetune) (0.8.10)\n",
            "Collecting tensorflow-addons==0.11.2\n",
            "  Downloading tensorflow_addons-0.11.2-cp37-cp37m-manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 58.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-estimator in /usr/local/lib/python3.7/dist-packages (from finetune) (2.8.0)\n",
            "Collecting tqdl==0.0.4\n",
            "  Downloading tqdl-0.0.4-py3-none-any.whl (4.7 kB)\n",
            "Collecting psutil==5.7.0\n",
            "  Downloading psutil-5.7.0.tar.gz (449 kB)\n",
            "\u001b[K     |████████████████████████████████| 449 kB 73.4 MB/s \n",
            "\u001b[?25hCollecting transformers==4.5.1\n",
            "  Downloading transformers-4.5.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 40.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons==0.11.2->finetune) (2.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from tqdl==0.0.4->finetune) (2.23.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 54.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1->finetune) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1->finetune) (3.8.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1->finetune) (4.12.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 48.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4>=0.0.1->finetune) (4.6.3)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy>=4.4.0->finetune) (0.2.5)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.8.0->finetune) (1.5.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.2.4->finetune) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.1->finetune) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.1->finetune) (2022.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23.1->finetune) (1.15.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.0.0->finetune) (2.0.6)\n",
            "Collecting catalogue<1.1.0,>=0.0.7\n",
            "  Downloading catalogue-1.0.0-py2.py3-none-any.whl (7.7 kB)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.0.0->finetune) (0.10.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.0.0->finetune) (57.4.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.0.0->finetune) (0.7.8)\n",
            "Collecting plac<1.2.0,>=0.9.6\n",
            "  Downloading plac-1.1.3-py2.py3-none-any.whl (20 kB)\n",
            "Collecting thinc<7.5.0,>=7.4.1\n",
            "  Downloading thinc-7.4.5-cp37-cp37m-manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 52.3 MB/s \n",
            "\u001b[?25hCollecting srsly<1.1.0,>=1.0.2\n",
            "  Downloading srsly-1.0.5-cp37-cp37m-manylinux2014_x86_64.whl (184 kB)\n",
            "\u001b[K     |████████████████████████████████| 184 kB 24.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.0.0->finetune) (3.0.7)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.0.0->finetune) (1.0.8)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.5.1->finetune) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.5.1->finetune) (3.8.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->tqdl==0.0.4->finetune) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->tqdl==0.0.4->finetune) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->tqdl==0.0.4->finetune) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->tqdl==0.0.4->finetune) (2022.6.15)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.5.1->finetune) (3.0.9)\n",
            "Building wheels for collected packages: finetune, psutil, sacremoses\n",
            "  Building wheel for finetune (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for finetune: filename=finetune-0.9.0-py3-none-any.whl size=920428 sha256=7a241130f6be2a5b23260e0c09faa2c8df01eb319ce30913110139141cdb705b\n",
            "  Stored in directory: /root/.cache/pip/wheels/14/d5/06/2a006e9cb4e3c77aa60f7eb0cc5c8f720b792c7d0ebe33b7b7\n",
            "  Building wheel for psutil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for psutil: filename=psutil-5.7.0-cp37-cp37m-linux_x86_64.whl size=276562 sha256=f38cad4f2655e7da680b27d9b9cbc0eb0f3020d5e9f91ac6f56a3b0dfd508cc6\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/e7/50/aee9cc966163d74430f13f208171dee22f11efa4a4a826661c\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=7e8e99f90f56d7687e6b6e69b1fc013d34871324c5eb6f1e39fea9283ccac132\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built finetune psutil sacremoses\n",
            "Installing collected packages: srsly, plac, catalogue, tokenizers, thinc, scikit-learn, sacremoses, transformers, tqdl, tensorflow-addons, spacy, sentencepiece, psutil, imbalanced-learn, ftfy, finetune\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 2.4.4\n",
            "    Uninstalling srsly-2.4.4:\n",
            "      Successfully uninstalled srsly-2.4.4\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 2.0.8\n",
            "    Uninstalling catalogue-2.0.8:\n",
            "      Successfully uninstalled catalogue-2.0.8\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.1.0\n",
            "    Uninstalling thinc-8.1.0:\n",
            "      Successfully uninstalled thinc-8.1.0\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.4.1\n",
            "    Uninstalling spacy-3.4.1:\n",
            "      Successfully uninstalled spacy-3.4.1\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "  Attempting uninstall: imbalanced-learn\n",
            "    Found existing installation: imbalanced-learn 0.8.1\n",
            "    Uninstalling imbalanced-learn-0.8.1:\n",
            "      Successfully uninstalled imbalanced-learn-0.8.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.22.2.post1 which is incompatible.\n",
            "en-core-web-sm 3.4.0 requires spacy<3.5.0,>=3.4.0, but you have spacy 2.3.7 which is incompatible.\u001b[0m\n",
            "Successfully installed catalogue-1.0.0 finetune-0.9.0 ftfy-6.1.1 imbalanced-learn-0.6.2 plac-1.1.3 psutil-5.7.0 sacremoses-0.0.53 scikit-learn-0.22.2.post1 sentencepiece-0.1.97 spacy-2.3.7 srsly-1.0.5 tensorflow-addons-0.11.2 thinc-7.4.5 tokenizers-0.10.3 tqdl-0.0.4 transformers-4.5.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip3 install finetune"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Start here after ```pip install finetune``` and reboot kernel"
      ],
      "metadata": {
        "id": "VhxFNmnZ3iaY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from finetune import MultiLabelClassifier # not used\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "PHaHS6bKuKxi",
        "outputId": "6ac1d29e-0d7c-4255-a2cc-8ce5ca478de3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:68: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.2.0 and strictly below 2.4.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.8.2 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/finetune/custom_ops/indico_tf_ops/python/indico_ops.py:29: UserWarning: Cuda appears to be available but cannot load the kernels\n",
            "  warnings.warn(\"Cuda appears to be available but cannot load the kernels\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example to use finetune, feel free to skip these"
      ],
      "metadata": {
        "id": "DdSTbhCt42lk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\"example, uncomment to run\"\n",
        "from finetune.datasets.mcdonalds_yelp_sentiment import MCDonaldsSentiment # we don't need this\n",
        "dataset = MCDonaldsSentiment().dataframe\n",
        "model = MultiLabelClassifier(n_epochs=2)\n",
        "trainX, testX, trainY, testY = train_test_split(dataset.Text, dataset.Target, test_size=0.3, random_state=42)\n",
        "model.fit(trainX, trainY)\n",
        "for threshold in np.linspace(0, 1, 5):\n",
        "    print(\"Threshold = {}\".format(threshold))\n",
        "    print(classification_report(\n",
        "        model.input_pipeline.label_encoder.transform(testY),\n",
        "        model.input_pipeline.label_encoder.transform(model.predict(testX, threshold=threshold))\n",
        "    ))\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "5spS8dXvtyAq",
        "outputId": "df3609db-733d-4abc-8fb4-7922f200ccc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: roberta-model-sm-v2.jl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 328M/328M [00:26<00:00, 12.2MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: dict.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 603k/603k [00:01<00:00, 524kiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: roberta_vocab.bpe\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 456k/456k [00:01<00:00, 399kiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: roberta_encoder.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 899k/899k [00:01<00:00, 658kiB/s] \n",
            "INFO:finetune:Saving tensorboard output to /tmp/Finetuneitw0arfl\n",
            "INFO:finetune: Visible GPUs: {GPU:/physical_device:GPU:0}\n",
            "Epoch 2/2: 100%|██████████| 1063/1063 [01:12<00:00, 14.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold = 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference: 0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/finetune/base_models/bert/modeling.py:818: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  kernel_initializer=create_initializer(initializer_range),\n",
            "/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  return layer.apply(inputs)\n",
            "/usr/local/lib/python3.7/dist-packages/finetune/base_models/bert/modeling.py:827: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  kernel_initializer=create_initializer(initializer_range),\n",
            "/usr/local/lib/python3.7/dist-packages/finetune/base_models/bert/modeling.py:836: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  kernel_initializer=create_initializer(initializer_range),\n",
            "/usr/local/lib/python3.7/dist-packages/finetune/base_models/bert/modeling.py:954: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  kernel_initializer=create_initializer(initializer_range))\n",
            "/usr/local/lib/python3.7/dist-packages/finetune/base_models/bert/modeling.py:964: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  kernel_initializer=create_initializer(initializer_range))\n",
            "/usr/local/lib/python3.7/dist-packages/finetune/base_models/bert/modeling.py:971: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  kernel_initializer=create_initializer(initializer_range))\n",
            "Inference: 452it [00:10, 41.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.34      1.00      0.51       152\n",
            "           1       0.78      1.00      0.88       346\n",
            "           2       1.00      1.00      1.00       442\n",
            "           3       0.34      1.00      0.51       152\n",
            "           4       0.17      1.00      0.29        74\n",
            "           5       0.03      1.00      0.07        15\n",
            "           6       0.10      1.00      0.19        46\n",
            "           7       0.27      1.00      0.43       121\n",
            "           8       0.13      1.00      0.24        59\n",
            "           9       0.21      1.00      0.35        95\n",
            "          10       0.21      1.00      0.35        95\n",
            "          11       0.32      1.00      0.49       143\n",
            "          12       0.55      1.00      0.71       241\n",
            "          13       1.00      1.00      1.00       442\n",
            "          14       1.00      1.00      1.00       442\n",
            "          15       0.26      1.00      0.42       116\n",
            "          16       0.21      1.00      0.35        95\n",
            "          17       0.55      1.00      0.71       241\n",
            "          18       0.59      1.00      0.74       262\n",
            "          19       0.57      1.00      0.72       250\n",
            "          20       0.03      1.00      0.06        14\n",
            "          21       0.10      1.00      0.18        43\n",
            "          22       0.55      1.00      0.71       245\n",
            "          23       0.46      1.00      0.63       202\n",
            "          24       0.21      1.00      0.35        95\n",
            "          25       0.03      1.00      0.06        14\n",
            "          26       0.56      1.00      0.72       246\n",
            "          27       0.63      1.00      0.77       279\n",
            "          28       0.16      1.00      0.28        71\n",
            "          29       0.13      1.00      0.23        58\n",
            "          30       0.32      1.00      0.49       143\n",
            "          31       0.47      1.00      0.64       209\n",
            "          32       0.23      1.00      0.37       101\n",
            "          33       0.18      1.00      0.31        80\n",
            "\n",
            "   micro avg       0.37      1.00      0.54      5629\n",
            "   macro avg       0.37      1.00      0.49      5629\n",
            "weighted avg       0.57      1.00      0.68      5629\n",
            " samples avg       0.37      1.00      0.52      5629\n",
            "\n",
            "Threshold = 0.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inference: 452it [00:09, 45.38it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.88      0.65       152\n",
            "           1       0.82      1.00      0.90       346\n",
            "           2       1.00      1.00      1.00       442\n",
            "           3       0.50      0.87      0.64       152\n",
            "           4       0.36      0.73      0.49        74\n",
            "           5       0.00      0.00      0.00        15\n",
            "           6       0.86      0.26      0.40        46\n",
            "           7       0.35      0.88      0.50       121\n",
            "           8       0.80      0.20      0.32        59\n",
            "           9       0.56      0.96      0.71        95\n",
            "          10       0.53      0.97      0.68        95\n",
            "          11       0.54      0.92      0.68       143\n",
            "          12       0.74      0.96      0.84       241\n",
            "          13       1.00      1.00      1.00       442\n",
            "          14       1.00      1.00      1.00       442\n",
            "          15       0.42      0.77      0.54       116\n",
            "          16       0.56      0.98      0.72        95\n",
            "          17       0.72      0.96      0.83       241\n",
            "          18       0.73      0.98      0.83       262\n",
            "          19       0.78      0.97      0.87       250\n",
            "          20       0.00      0.00      0.00        14\n",
            "          21       0.00      0.00      0.00        43\n",
            "          22       0.75      0.93      0.83       245\n",
            "          23       0.61      0.91      0.73       202\n",
            "          24       0.55      0.97      0.70        95\n",
            "          25       0.00      0.00      0.00        14\n",
            "          26       0.68      0.98      0.80       246\n",
            "          27       0.77      0.98      0.86       279\n",
            "          28       0.49      0.41      0.45        71\n",
            "          29       0.50      0.12      0.19        58\n",
            "          30       0.57      0.93      0.71       143\n",
            "          31       0.68      0.96      0.80       209\n",
            "          32       0.46      0.87      0.60       101\n",
            "          33       0.63      0.61      0.62        80\n",
            "\n",
            "   micro avg       0.69      0.91      0.79      5629\n",
            "   macro avg       0.57      0.73      0.61      5629\n",
            "weighted avg       0.72      0.91      0.79      5629\n",
            " samples avg       0.70      0.92      0.77      5629\n",
            "\n",
            "Threshold = 0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inference: 452it [00:10, 45.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.66      0.64       152\n",
            "           1       0.93      0.95      0.94       346\n",
            "           2       1.00      1.00      1.00       442\n",
            "           3       0.59      0.68      0.63       152\n",
            "           4       0.88      0.20      0.33        74\n",
            "           5       0.00      0.00      0.00        15\n",
            "           6       0.00      0.00      0.00        46\n",
            "           7       0.94      0.24      0.38       121\n",
            "           8       0.00      0.00      0.00        59\n",
            "           9       0.84      0.71      0.77        95\n",
            "          10       0.79      0.73      0.76        95\n",
            "          11       0.73      0.80      0.76       143\n",
            "          12       0.83      0.87      0.85       241\n",
            "          13       1.00      1.00      1.00       442\n",
            "          14       1.00      1.00      1.00       442\n",
            "          15       0.94      0.14      0.24       116\n",
            "          16       0.82      0.74      0.78        95\n",
            "          17       0.82      0.88      0.85       241\n",
            "          18       0.85      0.89      0.87       262\n",
            "          19       0.84      0.92      0.88       250\n",
            "          20       0.00      0.00      0.00        14\n",
            "          21       0.00      0.00      0.00        43\n",
            "          22       0.82      0.87      0.84       245\n",
            "          23       0.80      0.80      0.80       202\n",
            "          24       0.80      0.74      0.77        95\n",
            "          25       0.00      0.00      0.00        14\n",
            "          26       0.80      0.85      0.83       246\n",
            "          27       0.86      0.91      0.88       279\n",
            "          28       0.00      0.00      0.00        71\n",
            "          29       0.00      0.00      0.00        58\n",
            "          30       0.75      0.80      0.78       143\n",
            "          31       0.80      0.89      0.84       209\n",
            "          32       0.77      0.64      0.70       101\n",
            "          33       1.00      0.12      0.22        80\n",
            "\n",
            "   micro avg       0.86      0.78      0.82      5629\n",
            "   macro avg       0.64      0.56      0.57      5629\n",
            "weighted avg       0.82      0.78      0.78      5629\n",
            " samples avg       0.89      0.82      0.82      5629\n",
            "\n",
            "Threshold = 0.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inference: 452it [00:10, 42.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.01      0.03       152\n",
            "           1       0.96      0.84      0.90       346\n",
            "           2       1.00      1.00      1.00       442\n",
            "           3       0.83      0.07      0.12       152\n",
            "           4       0.00      0.00      0.00        74\n",
            "           5       0.00      0.00      0.00        15\n",
            "           6       0.00      0.00      0.00        46\n",
            "           7       0.00      0.00      0.00       121\n",
            "           8       0.00      0.00      0.00        59\n",
            "           9       0.75      0.03      0.06        95\n",
            "          10       0.83      0.05      0.10        95\n",
            "          11       0.94      0.43      0.59       143\n",
            "          12       0.88      0.69      0.77       241\n",
            "          13       1.00      1.00      1.00       442\n",
            "          14       1.00      1.00      1.00       442\n",
            "          15       0.00      0.00      0.00       116\n",
            "          16       0.93      0.29      0.45        95\n",
            "          17       0.89      0.71      0.79       241\n",
            "          18       0.91      0.72      0.81       262\n",
            "          19       0.92      0.84      0.88       250\n",
            "          20       0.00      0.00      0.00        14\n",
            "          21       0.00      0.00      0.00        43\n",
            "          22       0.92      0.70      0.80       245\n",
            "          23       0.88      0.59      0.71       202\n",
            "          24       0.92      0.25      0.40        95\n",
            "          25       0.00      0.00      0.00        14\n",
            "          26       0.91      0.62      0.74       246\n",
            "          27       0.91      0.79      0.85       279\n",
            "          28       0.00      0.00      0.00        71\n",
            "          29       0.00      0.00      0.00        58\n",
            "          30       0.95      0.48      0.64       143\n",
            "          31       0.90      0.70      0.79       209\n",
            "          32       1.00      0.19      0.32       101\n",
            "          33       0.00      0.00      0.00        80\n",
            "\n",
            "   micro avg       0.95      0.60      0.74      5629\n",
            "   macro avg       0.59      0.35      0.40      5629\n",
            "weighted avg       0.82      0.60      0.66      5629\n",
            " samples avg       0.96      0.68      0.75      5629\n",
            "\n",
            "Threshold = 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inference: 452it [00:10, 44.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       152\n",
            "           1       0.00      0.00      0.00       346\n",
            "           2       0.00      0.00      0.00       442\n",
            "           3       0.00      0.00      0.00       152\n",
            "           4       0.00      0.00      0.00        74\n",
            "           5       0.00      0.00      0.00        15\n",
            "           6       0.00      0.00      0.00        46\n",
            "           7       0.00      0.00      0.00       121\n",
            "           8       0.00      0.00      0.00        59\n",
            "           9       0.00      0.00      0.00        95\n",
            "          10       0.00      0.00      0.00        95\n",
            "          11       0.00      0.00      0.00       143\n",
            "          12       0.00      0.00      0.00       241\n",
            "          13       0.00      0.00      0.00       442\n",
            "          14       0.00      0.00      0.00       442\n",
            "          15       0.00      0.00      0.00       116\n",
            "          16       0.00      0.00      0.00        95\n",
            "          17       0.00      0.00      0.00       241\n",
            "          18       0.00      0.00      0.00       262\n",
            "          19       0.00      0.00      0.00       250\n",
            "          20       0.00      0.00      0.00        14\n",
            "          21       0.00      0.00      0.00        43\n",
            "          22       0.00      0.00      0.00       245\n",
            "          23       0.00      0.00      0.00       202\n",
            "          24       0.00      0.00      0.00        95\n",
            "          25       0.00      0.00      0.00        14\n",
            "          26       0.00      0.00      0.00       246\n",
            "          27       0.00      0.00      0.00       279\n",
            "          28       0.00      0.00      0.00        71\n",
            "          29       0.00      0.00      0.00        58\n",
            "          30       0.00      0.00      0.00       143\n",
            "          31       0.00      0.00      0.00       209\n",
            "          32       0.00      0.00      0.00       101\n",
            "          33       0.00      0.00      0.00        80\n",
            "\n",
            "   micro avg       0.00      0.00      0.00      5629\n",
            "   macro avg       0.00      0.00      0.00      5629\n",
            "weighted avg       0.00      0.00      0.00      5629\n",
            " samples avg       0.00      0.00      0.00      5629\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"dataset.head()\"\"\""
      ],
      "metadata": {
        "id": "tJue4axluq_B",
        "outputId": "c704ea02-b0ee-4f9e-f414-bc8bfcb95499",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                Text  \\\n",
              "0  I'm not a huge mcds lover, but I've been to be...   \n",
              "1  Terrible customer service. ÃÂ¾I came in at 9:...   \n",
              "2  First they \"lost\" my order, actually they gave...   \n",
              "3  I see I'm not the only one giving 1 star. Only...   \n",
              "4  Well, it's McDonald's, so you know what the fo...   \n",
              "\n",
              "                                          Target  \n",
              "0  [\"['RudeService', 'OrderProblem', 'Filthy']\"]  \n",
              "1                            [\"['RudeService']\"]  \n",
              "2            [\"['SlowService', 'OrderProblem']\"]  \n",
              "3                                         ['[]']  \n",
              "4                            [\"['RudeService']\"]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9bd3c448-31d6-46e1-bc59-9b2d66708732\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I'm not a huge mcds lover, but I've been to be...</td>\n",
              "      <td>[\"['RudeService', 'OrderProblem', 'Filthy']\"]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Terrible customer service. ÃÂ¾I came in at 9:...</td>\n",
              "      <td>[\"['RudeService']\"]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>First they \"lost\" my order, actually they gave...</td>\n",
              "      <td>[\"['SlowService', 'OrderProblem']\"]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I see I'm not the only one giving 1 star. Only...</td>\n",
              "      <td>['[]']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Well, it's McDonald's, so you know what the fo...</td>\n",
              "      <td>[\"['RudeService']\"]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9bd3c448-31d6-46e1-bc59-9b2d66708732')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9bd3c448-31d6-46e1-bc59-9b2d66708732 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9bd3c448-31d6-46e1-bc59-9b2d66708732');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"type(dataset[\"Text\"][0]), type(dataset[\"Target\"][0])\"\"\""
      ],
      "metadata": {
        "id": "ZWbyMtA4w7Xi",
        "outputId": "23be89e9-8f12-455c-d5eb-1c9f033507a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(str, str)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"trainX.head()\"\"\""
      ],
      "metadata": {
        "id": "zVxEv5eaxTNT",
        "outputId": "02a1215e-3832-4839-935b-fe7f7964a5cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "135     Worst McDonalds EVER!!!!!!!!!! They are unable...\n",
              "1098    Not lovin' it. ÃÂ¾Messed up a filet-o-fish. Ã...\n",
              "477     I was just there a few days ago. ÃÂ¾I ordered...\n",
              "974     I don't like this place at all, It is always d...\n",
              "435     This has gotta be the cheapest McDonalds in Mc...\n",
              "Name: Text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"trainY.head()\"\"\""
      ],
      "metadata": {
        "id": "nPBqVrSSxIlF",
        "outputId": "6436c10a-9a51-49d9-d82e-00c7b8460a0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "135     [\"['RudeService', 'OrderProblem']\"]\n",
              "1098     [\"['SlowService', 'RudeService']\"]\n",
              "477                     [\"['RudeService']\"]\n",
              "974          [\"['Filthy', 'OrderProblem']\"]\n",
              "435                     [\"['RudeService']\"]\n",
              "Name: Target, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"dataset.Text\"\"\""
      ],
      "metadata": {
        "id": "hb553s38xyXk",
        "outputId": "7e160cb6-ab95-46ae-912c-099e3bd6fa96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       I'm not a huge mcds lover, but I've been to be...\n",
              "1       Terrible customer service. ÃÂ¾I came in at 9:...\n",
              "2       First they \"lost\" my order, actually they gave...\n",
              "3       I see I'm not the only one giving 1 star. Only...\n",
              "4       Well, it's McDonald's, so you know what the fo...\n",
              "                              ...                        \n",
              "1466    I enjoyed the part where I repeatedly asked if...\n",
              "1467    Worst McDonalds I've been in in a long time! D...\n",
              "1468    When I am really craving for McDonald's, this ...\n",
              "1469    Two points right out of the gate: 1. Thuggery ...\n",
              "1470    I wanted to grab breakfast one morning before ...\n",
              "Name: Text, Length: 1471, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Play around with twitter ds and see if roberta works in tensorflow (aka here)"
      ],
      "metadata": {
        "id": "qaQmJd34v3FG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"twitter emo dataset\"\n",
        "!wget https://www.dropbox.com/s/ikkqxfdbdec3fuj/test.txt"
      ],
      "metadata": {
        "id": "2ve4NWEbv_Bl",
        "outputId": "edc7313d-263b-4dd9-b274-9a7126c81ebe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-26 13:46:01--  https://www.dropbox.com/s/ikkqxfdbdec3fuj/test.txt\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.3.18, 2620:100:601b:18::a27d:812\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.3.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/ikkqxfdbdec3fuj/test.txt [following]\n",
            "--2022-08-26 13:46:01--  https://www.dropbox.com/s/raw/ikkqxfdbdec3fuj/test.txt\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uce1c8a4b757305adbbd850091ab.dl.dropboxusercontent.com/cd/0/inline/BrsluKoa_25UrdzM5fxcqukQDfCy3s41l8y1QEPTbvyZi3xcqt-0Gg7J7bfiuuA9y8TknOWRJUhyXH08QhmLqjN1tepybe6sPdNFU46g7M8JuSyux9SdA0nqWWXUtkDyNd6CCQbfRAJxLLlssarhLEapREuYH2xG9XTSvmzx49TMEQ/file# [following]\n",
            "--2022-08-26 13:46:02--  https://uce1c8a4b757305adbbd850091ab.dl.dropboxusercontent.com/cd/0/inline/BrsluKoa_25UrdzM5fxcqukQDfCy3s41l8y1QEPTbvyZi3xcqt-0Gg7J7bfiuuA9y8TknOWRJUhyXH08QhmLqjN1tepybe6sPdNFU46g7M8JuSyux9SdA0nqWWXUtkDyNd6CCQbfRAJxLLlssarhLEapREuYH2xG9XTSvmzx49TMEQ/file\n",
            "Resolving uce1c8a4b757305adbbd850091ab.dl.dropboxusercontent.com (uce1c8a4b757305adbbd850091ab.dl.dropboxusercontent.com)... 162.125.3.15, 2620:100:6018:15::a27d:30f\n",
            "Connecting to uce1c8a4b757305adbbd850091ab.dl.dropboxusercontent.com (uce1c8a4b757305adbbd850091ab.dl.dropboxusercontent.com)|162.125.3.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 206760 (202K) [text/plain]\n",
            "Saving to: ‘test.txt’\n",
            "\n",
            "test.txt            100%[===================>] 201.91K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2022-08-26 13:46:02 (4.97 MB/s) - ‘test.txt’ saved [206760/206760]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "path = \"test.txt\"\n",
        "data_column = \"text\"\n",
        "class_column = \"class\"\n",
        "data = pd.read_csv(path, sep=\";\", header=None, names=[data_column, class_column], engine=\"python\")\n",
        "data.head()"
      ],
      "metadata": {
        "id": "lxdoWjN9wCEt",
        "outputId": "6f5e560f-0c69-433e-da61-845c8243fe4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text    class\n",
              "0  im feeling rather rotten so im not very ambiti...  sadness\n",
              "1          im updating my blog because i feel shitty  sadness\n",
              "2  i never make her separate from me because i do...  sadness\n",
              "3  i left with my bouquet of red and yellow tulip...      joy\n",
              "4    i was feeling a little vain when i did this one  sadness"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c218d5ce-7600-4868-a012-f1716b3460c1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>im feeling rather rotten so im not very ambiti...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>im updating my blog because i feel shitty</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i never make her separate from me because i do...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i left with my bouquet of red and yellow tulip...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i was feeling a little vain when i did this one</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c218d5ce-7600-4868-a012-f1716b3460c1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c218d5ce-7600-4868-a012-f1716b3460c1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c218d5ce-7600-4868-a012-f1716b3460c1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"go and write it as <class 'pandas.core.series.Series'>, now it's <class 'pandas.core.frame.DataFrame'>\""
      ],
      "metadata": {
        "id": "VNVUhaMNy6AH",
        "outputId": "7204888c-1110-4c01-d3e9-a3ecedce063a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"go and write it as <class 'pandas.core.series.Series'>, now it's <class 'pandas.core.frame.DataFrame'>\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"convert pandas dataframe to pandas series to use this library (finetune library)\"\n",
        "def get_pd_series(data, col):\n",
        "  return pd.DataFrame(data, columns=[col]).squeeze()\n",
        "\n",
        "x = get_pd_series(data, col=\"text\")\n",
        "x.head(), type(x)"
      ],
      "metadata": {
        "id": "8g16gvG70iig",
        "outputId": "49d1e02a-5c95-47b7-b5aa-13a76c5bb9b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0    im feeling rather rotten so im not very ambiti...\n",
              " 1            im updating my blog because i feel shitty\n",
              " 2    i never make her separate from me because i do...\n",
              " 3    i left with my bouquet of red and yellow tulip...\n",
              " 4      i was feeling a little vain when i did this one\n",
              " Name: text, dtype: object, pandas.core.series.Series)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = get_pd_series(data, col=\"class\")\n",
        "y.head(), type(y)"
      ],
      "metadata": {
        "id": "ya8ByA571Es4",
        "outputId": "dd3ccb47-c395-402a-ef4f-791cea80c342",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0    sadness\n",
              " 1    sadness\n",
              " 2    sadness\n",
              " 3        joy\n",
              " 4    sadness\n",
              " Name: class, dtype: object, pandas.core.series.Series)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainX, testX, trainY, testY = train_test_split(x, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "6RuYpCum5JTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset(data, x_col, y_col, **kwargs):\n",
        "  \"get dataset with train test split\"\n",
        "  x = get_pd_series(data, col = x_col)\n",
        "  y = get_pd_series(data, col = y_col)\n",
        "  return train_test_split(x, y, **kwargs)"
      ],
      "metadata": {
        "id": "KM2KO_YkYHKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert [a.all() == b.all() for a,b in zip(get_dataset(data, x_col=0, y_col=1, test_size=0.3, random_state=42), (trainX, testX, trainY, testY))]"
      ],
      "metadata": {
        "id": "0x_eGqy1Y54L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\"of course the result is bad, since it's not the model we choose (see below)\"\n",
        "model.fit(trainX, trainY)\n",
        "for threshold in np.linspace(0, 1, 5):\n",
        "    print(\"Threshold = {}\".format(threshold))\n",
        "    print(classification_report(\n",
        "        model.input_pipeline.label_encoder.transform(testY),\n",
        "        model.input_pipeline.label_encoder.transform(model.predict(testX, threshold=threshold))\n",
        "    ))\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "uDFfMr1W1grl",
        "outputId": "3ba8ab87-b661-4b84-ed68-5e9f1f75ebbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\"of course the result is bad, since it\\'s not the model we choose (see below)\"\\nmodel.fit(trainX, trainY)\\nfor threshold in np.linspace(0, 1, 5):\\n    print(\"Threshold = {}\".format(threshold))\\n    print(classification_report(\\n        model.input_pipeline.label_encoder.transform(testY),\\n        model.input_pipeline.label_encoder.transform(model.predict(testX, threshold=threshold))\\n    ))\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Roberta is the model we choose for this competition!"
      ],
      "metadata": {
        "id": "dTaS_qp13_ZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"Works\"\n",
        "\"try our bert you mofo\"\n",
        "#from finetune.base_models import BERT, RoBERTa, GPT, GPT2, TextCNN, TCN\n",
        "from finetune import Classifier\n",
        "from finetune.base_models import RoBERTa\n",
        "model_ = Classifier(base_model=RoBERTa)\n",
        "model_.fit(trainX, trainY)"
      ],
      "metadata": {
        "id": "XB0zpj-b1wdV",
        "outputId": "0c55ba93-15d4-4d13-abca-07371f963881",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:finetune:Saving tensorboard output to /tmp/Finetuneshvf0ora\n",
            "Epoch 8/8: 100%|██████████| 1400/1400 [00:59<00:00, 23.56it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"load in plurk ds as well\"\n",
        "!wget https://www.dropbox.com/s/dcnflgbssc8hich/plurk_dataset_processed.pkl\n",
        "\n",
        "import pickle\n",
        "\n",
        "with open(\"plurk_dataset_processed.pkl\", \"rb\") as f:\n",
        "  plurk_list = pickle.load(f)\n",
        "  f.close()\n",
        "plurk_list[:5]"
      ],
      "metadata": {
        "id": "LudgWmoZ2qJ2",
        "outputId": "bc44478d-ff46-4cd1-d8a5-04b904e32309",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-26 13:47:59--  https://www.dropbox.com/s/dcnflgbssc8hich/plurk_dataset_processed.pkl\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.3.18, 2620:100:601f:18::a27d:912\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.3.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/dcnflgbssc8hich/plurk_dataset_processed.pkl [following]\n",
            "--2022-08-26 13:48:00--  https://www.dropbox.com/s/raw/dcnflgbssc8hich/plurk_dataset_processed.pkl\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucc052af084bb79928178970bc29.dl.dropboxusercontent.com/cd/0/inline/BrtYX-Vpcgxcv8p1nMGjcvWSO0LXr1zpEwyV3hVkkcx_tTP1ItbA2mjJCUYSr0sDa8ROPspRfopJKUpKxyBRXeNkf1JPZBpL-h5O46ZDw5lD0m1NpMJEZbuc5HTTCwoVmW1Vjmxa3RO6Hc17qVjs7-e4g7W02BWRuIWdcJ-Ov3ajNQ/file# [following]\n",
            "--2022-08-26 13:48:00--  https://ucc052af084bb79928178970bc29.dl.dropboxusercontent.com/cd/0/inline/BrtYX-Vpcgxcv8p1nMGjcvWSO0LXr1zpEwyV3hVkkcx_tTP1ItbA2mjJCUYSr0sDa8ROPspRfopJKUpKxyBRXeNkf1JPZBpL-h5O46ZDw5lD0m1NpMJEZbuc5HTTCwoVmW1Vjmxa3RO6Hc17qVjs7-e4g7W02BWRuIWdcJ-Ov3ajNQ/file\n",
            "Resolving ucc052af084bb79928178970bc29.dl.dropboxusercontent.com (ucc052af084bb79928178970bc29.dl.dropboxusercontent.com)... 162.125.3.15, 2620:100:6018:15::a27d:30f\n",
            "Connecting to ucc052af084bb79928178970bc29.dl.dropboxusercontent.com (ucc052af084bb79928178970bc29.dl.dropboxusercontent.com)|162.125.3.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/BrsoO28SxRv7ghbXK7477s68tW7DGtR_nydmZ_0TiNXS8rgnvVPLpjqqIeNbI8Ft6NbX_5YIKl1TGbaTznWeRgs3pUZYDui1wOJwtEulpreAjPznD0ap_3asdupOeHxQz7YuqQSJsb9MnERDY2iugSgS92Zu5bA9s2zCDjpH8Hk0O2qlFzyqyB4mdcy8rDUEb85FTlPTctVrjC_WSakpA9CrjIhRKSQmUzI1RXpWy-8e29yQLvJgHJraFR-mg4zZWlS-Y-uIByEkQsBKVMHMpeWTlBV5HZt6BdNbAUOXIVSNiveEigmZCx_Yd7A-CKz6DkttR7uLuxp01KpOqqMhzXUFZFo0p7GFglekuLOAtAGhFJb1u-9aMlVq2HAh78-JbpSdkdnZcuJZWdOEe22kYeFeT2kxshSrRxZIMyn1n8jhBA/file [following]\n",
            "--2022-08-26 13:48:00--  https://ucc052af084bb79928178970bc29.dl.dropboxusercontent.com/cd/0/inline2/BrsoO28SxRv7ghbXK7477s68tW7DGtR_nydmZ_0TiNXS8rgnvVPLpjqqIeNbI8Ft6NbX_5YIKl1TGbaTznWeRgs3pUZYDui1wOJwtEulpreAjPznD0ap_3asdupOeHxQz7YuqQSJsb9MnERDY2iugSgS92Zu5bA9s2zCDjpH8Hk0O2qlFzyqyB4mdcy8rDUEb85FTlPTctVrjC_WSakpA9CrjIhRKSQmUzI1RXpWy-8e29yQLvJgHJraFR-mg4zZWlS-Y-uIByEkQsBKVMHMpeWTlBV5HZt6BdNbAUOXIVSNiveEigmZCx_Yd7A-CKz6DkttR7uLuxp01KpOqqMhzXUFZFo0p7GFglekuLOAtAGhFJb1u-9aMlVq2HAh78-JbpSdkdnZcuJZWdOEe22kYeFeT2kxshSrRxZIMyn1n8jhBA/file\n",
            "Reusing existing connection to ucc052af084bb79928178970bc29.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4802046 (4.6M) [application/octet-stream]\n",
            "Saving to: ‘plurk_dataset_processed.pkl’\n",
            "\n",
            "plurk_dataset_proce 100%[===================>]   4.58M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2022-08-26 13:48:01 (43.5 MB/s) - ‘plurk_dataset_processed.pkl’ saved [4802046/4802046]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('伴侶：臭貓貓 我玩遊戲的時候一直煩我，罵他還一直蹭我😡\\n（還是伴侶）\\n伴侶：我早上幫他乾洗澡後他就不讓我摸摸了😭', 3),\n",
              " ('😡\\n\\n好一天又罷工，我的腰好不爭氣', 3),\n",
              " ('有一種，終於結束的感覺了嗎？🤔\\n\\n在我之前的噗文裡，有一個叫「家蓉緋緋」的，\\n她當時在我還就職在寵物學校裡時，就讓我發現他是個很愛裝「我是無辜無害的」女人。\\n\\n她曾跟我說：「以前當學生時，都被其他人霸凌」\\n而我後來也跟他說：「你被霸凌是應該的，因為你處處要跟每個人好，你每個人都拼命想討好，所以你會被霸凌是正常的！」\\n\\n後來我離開寵美學校後，我也不再與他們聯絡，打死我都不會再聯絡的😡\\n\\n唯一一次的聯絡，是在去年傳了這個訊息給我😡\\n\\n後來這個截圖我拿去詢問較好的同行朋友，每個人都在說：「這個人是神經病嗎？他有問題是不是？分不清責任歸屬？」\\n\\n為何我會說這事情彷彿告一段落的原因是⋯這女人因為朋友關係，又退出所有學校相關的群組了👍',\n",
              "  3),\n",
              " ('[日韓擔的最怒] [知韓知日，學優明缺]\\n@enfihu - Kakao 想戰 Google ? 也是有影響到數位音樂平台付費喔！ 我有在ptt韓...\\n/ 前情提要\\n—\\n我開始覺得KBS 對不朽名曲/柳喜烈寫生簿/開放音樂會演出內容，管非韓國IP、是否更換/釋出多角度影片的『彈性標準』感到火大😡🤬\\n外飯的瀏覽權不重要嗎？ - 當然也有Content ID /版權等等因素\\n把我們當提款機嗎！',\n",
              "  3),\n",
              " ('中國「飛彈首次穿越台灣」 國防部告訴你為何不擊落、不公布、沒警報｜蘋果新聞網｜蘋果日報\\n真的有飛彈從上空飛過去 從上面飛過去這就過分了吧😡', 3)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"save it as %s as well\" % (type(trainX))"
      ],
      "metadata": {
        "id": "jS0Ooqk_3Pkk",
        "outputId": "1d00f794-2475-4699-e3e3-1b518509e67c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"save it as <class 'pandas.core.series.Series'> as well\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dd = pd.DataFrame(plurk_list[:10])\n",
        "dd.head(), type(dd)"
      ],
      "metadata": {
        "id": "yPQFCVDS3Tzx",
        "outputId": "5dba5bd5-57d7-454e-c2fd-faaac9fe5bc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(                                                   0  1\n",
              " 0  伴侶：臭貓貓 我玩遊戲的時候一直煩我，罵他還一直蹭我😡\\n（還是伴侶）\\n伴侶：我早上幫他乾...  3\n",
              " 1                                😡\\n\\n好一天又罷工，我的腰好不爭氣  3\n",
              " 2  有一種，終於結束的感覺了嗎？🤔\\n\\n在我之前的噗文裡，有一個叫「家蓉緋緋」的，\\n她當時在...  3\n",
              " 3  [日韓擔的最怒] [知韓知日，學優明缺]\\n@enfihu - Kakao 想戰 Googl...  3\n",
              " 4  中國「飛彈首次穿越台灣」 國防部告訴你為何不擊落、不公布、沒警報｜蘋果新聞網｜蘋果日報\\n真...  3,\n",
              " pandas.core.frame.DataFrame)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"data: %s; \\n\\nlabel: %s\" % (dd[0][0], dd[1][0]))"
      ],
      "metadata": {
        "id": "S7mydo0X3ehy",
        "outputId": "1efad803-ed70-42f5-8baf-efaae02da43d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data: 伴侶：臭貓貓 我玩遊戲的時候一直煩我，罵他還一直蹭我😡\n",
            "（還是伴侶）\n",
            "伴侶：我早上幫他乾洗澡後他就不讓我摸摸了😭; \n",
            "\n",
            "label: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plurk_frame = pd.DataFrame(plurk_list)\n",
        "# random_state -> shuffled!\n",
        "trainX, testX, trainY, testY = get_dataset(plurk_frame, x_col=0, y_col=1, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "rCUpWDMoaSUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(trainX)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMZpMMdNa5GH",
        "outputId": "ffb47d66-74f3-4534-f3c0-4d801578d5ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(list(trainY)[0])"
      ],
      "metadata": {
        "id": "LNmwtdfU7vx8",
        "outputId": "d94e9b92-5c84-43c3-9d65-9fd53dbccb4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "int"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from finetune import Classifier\n",
        "from finetune.base_models import RoBERTa\n",
        "model = Classifier(base_model=RoBERTa) # set n_epochs = some_number_less_than_8 to save time\n",
        "model.fit(trainX, trainY) # takes more than 2.5 hrs for n_epochs=8 (default setting)\n",
        "# for threshold in np.linspace(0, 1, 5):\n",
        "#     print(\"Threshold = {}\".format(threshold))\n",
        "#     print(classification_report(\n",
        "#         model.input_pipeline.label_encoder.transform(testY),\n",
        "#         model.input_pipeline.label_encoder.transform(model.predict(testX, threshold=threshold))\n",
        "#     ))\n"
      ],
      "metadata": {
        "id": "ZzXl8nOJ7lF3",
        "outputId": "0078b585-3289-4909-b2ab-13926d88d3f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: roberta-model-sm-v2.jl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 328M/328M [00:06<00:00, 53.8MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: dict.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 603k/603k [00:00<00:00, 4.11MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: roberta_vocab.bpe\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 456k/456k [00:00<00:00, 3.90MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: roberta_encoder.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 899k/899k [00:00<00:00, 5.54MiB/s]\n",
            "INFO:finetune:Saving tensorboard output to /tmp/Finetunebjgwrcjs\n",
            "INFO:finetune: Visible GPUs: {GPU:/physical_device:GPU:0}\n",
            "Epoch 8/8: 100%|██████████| 16929/16929 [19:24<00:00, 14.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold = 0.0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-0b97657809a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     print(classification_report(\n\u001b[1;32m      8\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     ))\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/finetune/target_models/classifier.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, context, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;34m[\u001b[0m  \u001b[0;36m1\u001b[0m  \u001b[0;34m|\u001b[0m  \u001b[0;36m1\u001b[0m  \u001b[0;34m|\u001b[0m  \u001b[0;36m2\u001b[0m  \u001b[0;34m|\u001b[0m  \u001b[0;36m3\u001b[0m  \u001b[0;34m|\u001b[0m  \u001b[0;36m3\u001b[0m  \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \"\"\"\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzipped_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/finetune/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, Xs, context, **kwargs)\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mzipped_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvert_idxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sort_by_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzipped_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzipped_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_by_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/finetune/target_models/classifier.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, zipped_data, probas, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mall_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mdoc_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_of_doc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_of_doc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_long_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzipped_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mdoc_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: process_long_sequence() got an unexpected keyword argument 'threshold'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_report = []\n",
        "for threshold in np.linspace(0, 1, 5):\n",
        "    print(\"Threshold = {}\".format(threshold))\n",
        "    result_report.append(\n",
        "        classification_report(\n",
        "        model.input_pipeline.label_encoder.transform(testY),\n",
        "        model.input_pipeline.label_encoder.transform(model.predict(testX))\n",
        "    ))\n",
        "\n",
        "for ele in result_report:\n",
        "  print(ele)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCqskOcb_aCs",
        "outputId": "10992bea-7e21-4708-af24-bfaf087599d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold = 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference: 0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/finetune/base_models/bert/modeling.py:818: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  kernel_initializer=create_initializer(initializer_range),\n",
            "/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  return layer.apply(inputs)\n",
            "/usr/local/lib/python3.7/dist-packages/finetune/base_models/bert/modeling.py:827: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  kernel_initializer=create_initializer(initializer_range),\n",
            "/usr/local/lib/python3.7/dist-packages/finetune/base_models/bert/modeling.py:836: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  kernel_initializer=create_initializer(initializer_range),\n",
            "/usr/local/lib/python3.7/dist-packages/finetune/base_models/bert/modeling.py:954: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  kernel_initializer=create_initializer(initializer_range))\n",
            "/usr/local/lib/python3.7/dist-packages/finetune/base_models/bert/modeling.py:964: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  kernel_initializer=create_initializer(initializer_range))\n",
            "/usr/local/lib/python3.7/dist-packages/finetune/base_models/bert/modeling.py:971: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  kernel_initializer=create_initializer(initializer_range))\n",
            "Inference: 7234it [02:26, 49.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold = 0.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inference: 7234it [01:44, 69.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold = 0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inference: 7234it [01:43, 69.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold = 0.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inference: 7234it [01:42, 70.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold = 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inference: 7234it [01:43, 69.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98      1652\n",
            "           1       0.97      0.99      0.98      2250\n",
            "           2       0.98      0.99      0.99      1980\n",
            "           3       0.97      0.98      0.98       491\n",
            "           4       0.96      0.99      0.98       239\n",
            "           5       0.98      0.97      0.98       441\n",
            "\n",
            "   micro avg       0.98      0.98      0.98      7053\n",
            "   macro avg       0.98      0.98      0.98      7053\n",
            "weighted avg       0.98      0.98      0.98      7053\n",
            " samples avg       0.98      0.98      0.98      7053\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98      1652\n",
            "           1       0.97      0.99      0.98      2250\n",
            "           2       0.98      0.99      0.99      1980\n",
            "           3       0.97      0.98      0.98       491\n",
            "           4       0.96      0.99      0.98       239\n",
            "           5       0.98      0.97      0.98       441\n",
            "\n",
            "   micro avg       0.98      0.98      0.98      7053\n",
            "   macro avg       0.98      0.98      0.98      7053\n",
            "weighted avg       0.98      0.98      0.98      7053\n",
            " samples avg       0.98      0.98      0.98      7053\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98      1652\n",
            "           1       0.97      0.99      0.98      2250\n",
            "           2       0.98      0.99      0.99      1980\n",
            "           3       0.97      0.98      0.98       491\n",
            "           4       0.96      0.99      0.98       239\n",
            "           5       0.98      0.97      0.98       441\n",
            "\n",
            "   micro avg       0.98      0.98      0.98      7053\n",
            "   macro avg       0.98      0.98      0.98      7053\n",
            "weighted avg       0.98      0.98      0.98      7053\n",
            " samples avg       0.98      0.98      0.98      7053\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98      1652\n",
            "           1       0.97      0.99      0.98      2250\n",
            "           2       0.98      0.99      0.99      1980\n",
            "           3       0.97      0.98      0.98       491\n",
            "           4       0.96      0.99      0.98       239\n",
            "           5       0.98      0.97      0.98       441\n",
            "\n",
            "   micro avg       0.98      0.98      0.98      7053\n",
            "   macro avg       0.98      0.98      0.98      7053\n",
            "weighted avg       0.98      0.98      0.98      7053\n",
            " samples avg       0.98      0.98      0.98      7053\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98      1652\n",
            "           1       0.97      0.99      0.98      2250\n",
            "           2       0.98      0.99      0.99      1980\n",
            "           3       0.97      0.98      0.98       491\n",
            "           4       0.96      0.99      0.98       239\n",
            "           5       0.98      0.97      0.98       441\n",
            "\n",
            "   micro avg       0.98      0.98      0.98      7053\n",
            "   macro avg       0.98      0.98      0.98      7053\n",
            "weighted avg       0.98      0.98      0.98      7053\n",
            " samples avg       0.98      0.98      0.98      7053\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save the model weight since it's taking too long"
      ],
      "metadata": {
        "id": "id8uy5TVe9Pe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "Si0kWz0EiAOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#%cd drive/MyDrive/AI_sheng"
      ],
      "metadata": {
        "id": "0uH2gH-c7tJA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9fc9a1a-aa5d-49b1-9d29-0b016520ab09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls drive/MyDrive/AI_sheng"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLj_fZKuCN7a",
        "outputId": "b0b97e6a-6c2b-4142-8bb1-f265df4d22e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 0704_run_example_LRFinder_failed   keys.txt\n",
            " 0706_batch_figured_out\t\t    keys.txt.pub\n",
            " emo_0_inference_only.pt\t    Tips_of_torch_on_colab.ipynb\n",
            " EMO_AI\t\t\t\t   'train_emo_model(original one)_better.ipynb'\n",
            " emo_in_tf_tryout.ipynb\t\t    ulmfit_example\n",
            " fine_tune_emo_on_plurk.ipynb\t    VA_model\n",
            " gradio_app_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path as P\n",
        "basedir = \"drive/MyDrive/AI_sheng\"\n",
        "filename = P(basedir)/\"emo_in_tf_0826\"\n",
        "# save as folder\n",
        "model.save(filename)"
      ],
      "metadata": {
        "id": "83HoEGVEf8Fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93sq1h_1ChHt",
        "outputId": "8c992f16-9c73-4c46-fc26-413401cf5587"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('drive/MyDrive/AI_sheng/emo_in_tf_0826')"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l drive/MyDrive/AI_sheng/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-T6zYFQiC5Wm",
        "outputId": "d12fe031-6696-4ab4-e900-af4a651b0f78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 805969\n",
            "drwx------ 2 root root      4096 Aug  8 04:52  0704_run_example_LRFinder_failed\n",
            "drwx------ 2 root root      4096 Jul  7 16:41  0706_batch_figured_out\n",
            "-rw------- 1 root root 328553579 Jul  6 03:48  emo_0_inference_only.pt\n",
            "drwx------ 2 root root      4096 Jul  5 05:13  EMO_AI\n",
            "-rw------- 1 root root 496282045 Aug 26 16:45  emo_in_tf_0826\n",
            "-rw------- 1 root root     83589 Aug 26 16:45  emo_in_tf_tryout.ipynb\n",
            "-rw------- 1 root root    180089 Aug 23 19:14  fine_tune_emo_on_plurk.ipynb\n",
            "-rw------- 1 root root     90297 Aug  9 07:29  gradio_app_0\n",
            "-rw------- 1 root root      3243 Jul  5 05:01  keys.txt\n",
            "-rw------- 1 root root       743 Jul  5 05:01  keys.txt.pub\n",
            "-rw------- 1 root root      3438 Aug 11 10:11  Tips_of_torch_on_colab.ipynb\n",
            "-rw------- 1 root root     92152 Aug 10 21:19 'train_emo_model(original one)_better.ipynb'\n",
            "drwx------ 2 root root      4096 Aug 11 07:08  ulmfit_example\n",
            "drwx------ 2 root root      4096 Aug  8 01:47  VA_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LF4jh45NDXPX",
        "outputId": "3868d050-d1d6-4e62-accc-1e77d5ce46d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('drive/MyDrive/AI_sheng/emo_in_tf_0826')"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"check if model.save works\"\n",
        "reload_m = Classifier.load(str(filename))\n",
        "reload_m.predict(testX[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFDRhvm1phOL",
        "outputId": "0f594fa8-8ecf-4c11-8f6d-4e9807b5d58c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:finetune:Saving tensorboard output to /tmp/Finetuneipy37ivs\n",
            "Inference: 0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/finetune/base_models/bert/modeling.py:818: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  kernel_initializer=create_initializer(initializer_range),\n",
            "/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  return layer.apply(inputs)\n",
            "/usr/local/lib/python3.7/dist-packages/finetune/base_models/bert/modeling.py:827: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  kernel_initializer=create_initializer(initializer_range),\n",
            "/usr/local/lib/python3.7/dist-packages/finetune/base_models/bert/modeling.py:836: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  kernel_initializer=create_initializer(initializer_range),\n",
            "/usr/local/lib/python3.7/dist-packages/finetune/base_models/bert/modeling.py:954: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  kernel_initializer=create_initializer(initializer_range))\n",
            "/usr/local/lib/python3.7/dist-packages/finetune/base_models/bert/modeling.py:964: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  kernel_initializer=create_initializer(initializer_range))\n",
            "/usr/local/lib/python3.7/dist-packages/finetune/base_models/bert/modeling.py:971: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  kernel_initializer=create_initializer(initializer_range))\n",
            "Inference: 56it [00:17,  3.15it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 4,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save the report as well"
      ],
      "metadata": {
        "id": "FcYJAODFIwp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cat drive/MyDrive/AI_sheng/result_report_0826.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLcAl3kGEuOH",
        "outputId": "9902fade-1507-4d35-d3ed-a98ff0d23f49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98      1652\n",
            "           1       0.97      0.99      0.98      2250\n",
            "           2       0.98      0.99      0.99      1980\n",
            "           3       0.97      0.98      0.98       491\n",
            "           4       0.96      0.99      0.98       239\n",
            "           5       0.98      0.97      0.98       441\n",
            "\n",
            "   micro avg       0.98      0.98      0.98      7053\n",
            "   macro avg       0.98      0.98      0.98      7053\n",
            "weighted avg       0.98      0.98      0.98      7053\n",
            " samples avg       0.98      0.98      0.98      7053\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98      1652\n",
            "           1       0.97      0.99      0.98      2250\n",
            "           2       0.98      0.99      0.99      1980\n",
            "           3       0.97      0.98      0.98       491\n",
            "           4       0.96      0.99      0.98       239\n",
            "           5       0.98      0.97      0.98       441\n",
            "\n",
            "   micro avg       0.98      0.98      0.98      7053\n",
            "   macro avg       0.98      0.98      0.98      7053\n",
            "weighted avg       0.98      0.98      0.98      7053\n",
            " samples avg       0.98      0.98      0.98      7053\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98      1652\n",
            "           1       0.97      0.99      0.98      2250\n",
            "           2       0.98      0.99      0.99      1980\n",
            "           3       0.97      0.98      0.98       491\n",
            "           4       0.96      0.99      0.98       239\n",
            "           5       0.98      0.97      0.98       441\n",
            "\n",
            "   micro avg       0.98      0.98      0.98      7053\n",
            "   macro avg       0.98      0.98      0.98      7053\n",
            "weighted avg       0.98      0.98      0.98      7053\n",
            " samples avg       0.98      0.98      0.98      7053\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98      1652\n",
            "           1       0.97      0.99      0.98      2250\n",
            "           2       0.98      0.99      0.99      1980\n",
            "           3       0.97      0.98      0.98       491\n",
            "           4       0.96      0.99      0.98       239\n",
            "           5       0.98      0.97      0.98       441\n",
            "\n",
            "   micro avg       0.98      0.98      0.98      7053\n",
            "   macro avg       0.98      0.98      0.98      7053\n",
            "weighted avg       0.98      0.98      0.98      7053\n",
            " samples avg       0.98      0.98      0.98      7053\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98      1652\n",
            "           1       0.97      0.99      0.98      2250\n",
            "           2       0.98      0.99      0.99      1980\n",
            "           3       0.97      0.98      0.98       491\n",
            "           4       0.96      0.99      0.98       239\n",
            "           5       0.98      0.97      0.98       441\n",
            "\n",
            "   micro avg       0.98      0.98      0.98      7053\n",
            "   macro avg       0.98      0.98      0.98      7053\n",
            "weighted avg       0.98      0.98      0.98      7053\n",
            " samples avg       0.98      0.98      0.98      7053\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l drive/MyDrive/AI_sheng/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oyUpsIlE9EY",
        "outputId": "233db400-a6a7-4c53-fd9e-caa91b1a71a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 805985\n",
            "drwx------ 2 root root      4096 Aug  8 04:52  0704_run_example_LRFinder_failed\n",
            "drwx------ 2 root root      4096 Jul  7 16:41  0706_batch_figured_out\n",
            "-rw------- 1 root root 328553579 Jul  6 03:48  emo_0_inference_only.pt\n",
            "drwx------ 2 root root      4096 Jul  5 05:13  EMO_AI\n",
            "-rw------- 1 root root 496282045 Aug 26 16:45  emo_in_tf_0826\n",
            "-rw------- 1 root root      4112 Aug 26 16:49  emo_in_tf_0826.pkl\n",
            "-rw------- 1 root root     93079 Aug 26 17:04  emo_in_tf_tryout.ipynb\n",
            "-rw------- 1 root root    180089 Aug 23 19:14  fine_tune_emo_on_plurk.ipynb\n",
            "-rw------- 1 root root     90297 Aug  9 07:29  gradio_app_0\n",
            "-rw------- 1 root root      3243 Jul  5 05:01  keys.txt\n",
            "-rw------- 1 root root       743 Jul  5 05:01  keys.txt.pub\n",
            "-rw------- 1 root root      2980 Aug 26 17:01  result_report_0826.txt\n",
            "-rw------- 1 root root      3438 Aug 11 10:11  Tips_of_torch_on_colab.ipynb\n",
            "-rw------- 1 root root     92152 Aug 10 21:19 'train_emo_model(original one)_better.ipynb'\n",
            "drwx------ 2 root root      4096 Aug 11 07:08  ulmfit_example\n",
            "drwx------ 2 root root      4096 Aug  8 01:47  VA_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert 1 == 0, \"stop here\""
      ],
      "metadata": {
        "id": "PL0-Y7Z8JH3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### somehow, predict doesnt' work for model\n",
        "### saved with pickle, don't use this"
      ],
      "metadata": {
        "id": "r1y9AQeIItoH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"save the model as pickle just in case the file format doesn't work\"\n",
        "filename_model = P(basedir)/\"emo_in_tf_0826.pkl\"\n",
        "if not filename_model.is_file():\n",
        "  with open(filename_model, \"wb\") as f:\n",
        "    pickle.dump(model, f)\n",
        "    f.close()\n",
        "else:\n",
        "  print(\"file existed, try again\")\n",
        "!ls drive/MyDrive/AI_sheng/emo_in_tf_0826.pkl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3lVGGDUg9fi",
        "outputId": "49abe291-5efd-41bf-99f7-e290eda7f202"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive/MyDrive/AI_sheng/emo_in_tf_0826.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l drive/MyDrive/AI_sheng/emo_in_tf_0826.pkl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDBoovIfDo49",
        "outputId": "4a075470-d664-472d-c7f5-ee2e49060705"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw------- 1 root root 4112 Aug 26 16:49 drive/MyDrive/AI_sheng/emo_in_tf_0826.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(filename_model, \"rb\") as f:\n",
        "  reload_model = pickle.load(f)\n",
        "  f.close()\n",
        "\n",
        "\n",
        "tmp = reload_model.predict(testX[0])\n",
        "tmp[:5], len(tmp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "G3co_lfzHoyD",
        "outputId": "c579881b-42f5-4242-f622-a5e288cf7c7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-afaf536475cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreload_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/finetune/target_models/classifier.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, context, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;34m[\u001b[0m  \u001b[0;36m1\u001b[0m  \u001b[0;34m|\u001b[0m  \u001b[0;36m1\u001b[0m  \u001b[0;34m|\u001b[0m  \u001b[0;36m2\u001b[0m  \u001b[0;34m|\u001b[0m  \u001b[0;36m3\u001b[0m  \u001b[0;34m|\u001b[0m  \u001b[0;36m3\u001b[0m  \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \"\"\"\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzipped_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/finetune/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, Xs, context, **kwargs)\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mzipped_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvert_idxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sort_by_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzipped_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzipped_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_by_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/finetune/target_models/classifier.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, zipped_data, probas, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mall_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mdoc_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_of_doc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_of_doc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_long_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzipped_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mdoc_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/finetune/base.py\u001b[0m in \u001b[0;36mprocess_long_sequence\u001b[0;34m(self, zipped_data)\u001b[0m\n\u001b[1;32m    906\u001b[0m             \u001b[0mpredict_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPredictMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPROBAS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPredictMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNORMAL\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0mchunked_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m             \u001b[0mlist_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m         )\n\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/finetune/base.py\u001b[0m in \u001b[0;36m_inference\u001b[0;34m(self, zipped_data, predict_keys, context, update_hook, chunked_length, list_output)\u001b[0m\n\u001b[1;32m    442\u001b[0m         estimator, hooks = self.get_estimator(\n\u001b[1;32m    443\u001b[0m             \u001b[0mbuild_explain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPredictMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXPLAIN\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredict_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m             \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_predict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m         )\n\u001b[1;32m    446\u001b[0m         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunked_length\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mchunked_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzipped_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Classifier' object has no attribute '_cached_predict'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"predict\" in dir(reload_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fA-Pnok1IQEO",
        "outputId": "03072142-cf99-42c8-9249-f182891093a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reload_model.predict(testX[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "SDCQnUp0Ict6",
        "outputId": "795f39e5-d6bc-4362-8ab4-012e78b273c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-234ee853b192>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreload_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/finetune/target_models/classifier.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, context, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;34m[\u001b[0m  \u001b[0;36m1\u001b[0m  \u001b[0;34m|\u001b[0m  \u001b[0;36m1\u001b[0m  \u001b[0;34m|\u001b[0m  \u001b[0;36m2\u001b[0m  \u001b[0;34m|\u001b[0m  \u001b[0;36m3\u001b[0m  \u001b[0;34m|\u001b[0m  \u001b[0;36m3\u001b[0m  \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \"\"\"\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzipped_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/finetune/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, Xs, context, **kwargs)\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mzipped_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvert_idxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sort_by_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzipped_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzipped_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_by_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/finetune/target_models/classifier.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, zipped_data, probas, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mall_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mdoc_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_of_doc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_of_doc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_long_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzipped_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mdoc_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/finetune/base.py\u001b[0m in \u001b[0;36mprocess_long_sequence\u001b[0;34m(self, zipped_data)\u001b[0m\n\u001b[1;32m    906\u001b[0m             \u001b[0mpredict_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPredictMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPROBAS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPredictMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNORMAL\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0mchunked_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m             \u001b[0mlist_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m         )\n\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/finetune/base.py\u001b[0m in \u001b[0;36m_inference\u001b[0;34m(self, zipped_data, predict_keys, context, update_hook, chunked_length, list_output)\u001b[0m\n\u001b[1;32m    442\u001b[0m         estimator, hooks = self.get_estimator(\n\u001b[1;32m    443\u001b[0m             \u001b[0mbuild_explain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPredictMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXPLAIN\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredict_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m             \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_predict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m         )\n\u001b[1;32m    446\u001b[0m         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunked_length\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mchunked_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzipped_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Classifier' object has no attribute '_cached_predict'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"save the result as well\"\n",
        "\n",
        "result_filename = P(basedir)/\"result_report_0826.txt\"\n",
        "\n",
        "if not result_filename.is_file():\n",
        "  with open(result_filename, \"w\") as f:\n",
        "    for ele in result_report:\n",
        "      f.write(ele)\n",
        "    f.close()\n",
        "else:\n",
        "  print(\"%s file exists, try again\" % str(result_filename))"
      ],
      "metadata": {
        "id": "tjBx5QMwDr_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5t9LXdP2HS6K"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "emo_in_tf_tryout.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "DdSTbhCt42lk",
        "r1y9AQeIItoH"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}