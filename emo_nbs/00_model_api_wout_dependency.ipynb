{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp from_scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's do this\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def test():\n",
    "    print(\"success\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take a look at the data (twitter emotion dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "read the data w/out upzip it (via script)\n",
    "\n",
    "tokenize the data (write a function for it since it'll be used for at least 3 times)\n",
    "\n",
    "hope tensorflow/pytorch would be able to read it directly\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read file without unzip not done, probably not important ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# read the file w/out unzip it\n",
    "\"\"\"by GeoHotz\"\"\"\n",
    "\n",
    "# this works but not so much for parser() # since we're doing language, not image\n",
    "def fetch(name,dataset_name='emotional.zip'):\n",
    "    import hashlib\n",
    "    import os\n",
    "    # generate encrypted file name to avoid collision ?\n",
    "    fp = os.path.join(os.getcwd(), hashlib.md5(\n",
    "        name.encode('utf-8')).hexdigest())\n",
    "    dat = None\n",
    "    if os.path.isfile(fp):\n",
    "        with open(fp, \"rb\") as f:\n",
    "            dat = f.read()\n",
    "    else:\n",
    "        import tempfile\n",
    "        from zipfile import ZipFile\n",
    "        # dat = requests.get(url).content\n",
    "        with ZipFile(dataset_name) as zip:\n",
    "            with zip.open(\"%s.csv\" % name, mode='r') as f:\n",
    "                dat = f.read()\n",
    "        # important trick here to create a .tmp file\n",
    "        with open(fp+\".tmp\", \"wb\") as f:\n",
    "            f.write(dat)\n",
    "        os.rename(fp+\".tmp\", fp)\n",
    "\n",
    "    return dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(dat): \n",
    "    import numpy as np\n",
    "    import gzip\n",
    "    return np.frombuffer(gzip.decompress(dat), dtype=np.uint8).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadGzipFile",
     "evalue": "Not a gzipped file (b'te')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadGzipFile\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Kelvin\\Documents\\GitHub\\EMO_AI\\00_core.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Kelvin/Documents/GitHub/EMO_AI/00_core.ipynb#ch0000011?line=0'>1</a>\u001b[0m tmp \u001b[39m=\u001b[39m parse(fetch(\u001b[39m\"\u001b[39;49m\u001b[39mtest\u001b[39;49m\u001b[39m\"\u001b[39;49m))[\u001b[39m0x8\u001b[39m:]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Kelvin/Documents/GitHub/EMO_AI/00_core.ipynb#ch0000011?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(tmp[\u001b[39m0\u001b[39m])\n",
      "\u001b[1;32mc:\\Users\\Kelvin\\Documents\\GitHub\\EMO_AI\\00_core.ipynb Cell 7'\u001b[0m in \u001b[0;36mparse\u001b[1;34m(dat)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Kelvin/Documents/GitHub/EMO_AI/00_core.ipynb#ch0000010?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Kelvin/Documents/GitHub/EMO_AI/00_core.ipynb#ch0000010?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mgzip\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Kelvin/Documents/GitHub/EMO_AI/00_core.ipynb#ch0000010?line=4'>5</a>\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mfrombuffer(gzip\u001b[39m.\u001b[39;49mdecompress(dat), dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39muint8)\u001b[39m.\u001b[39mcopy()\n",
      "File \u001b[1;32mc:\\Users\\Kelvin\\anaconda3\\envs\\fastAI\\lib\\gzip.py:548\u001b[0m, in \u001b[0;36mdecompress\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    544\u001b[0m \u001b[39m\"\"\"Decompress a gzip compressed string in one shot.\u001b[39;00m\n\u001b[0;32m    545\u001b[0m \u001b[39mReturn the decompressed string.\u001b[39;00m\n\u001b[0;32m    546\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \u001b[39mwith\u001b[39;00m GzipFile(fileobj\u001b[39m=\u001b[39mio\u001b[39m.\u001b[39mBytesIO(data)) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m--> 548\u001b[0m     \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39;49mread()\n",
      "File \u001b[1;32mc:\\Users\\Kelvin\\anaconda3\\envs\\fastAI\\lib\\gzip.py:292\u001b[0m, in \u001b[0;36mGzipFile.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39merrno\u001b[39;00m\n\u001b[0;32m    291\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(errno\u001b[39m.\u001b[39mEBADF, \u001b[39m\"\u001b[39m\u001b[39mread() on write-only GzipFile object\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 292\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_buffer\u001b[39m.\u001b[39;49mread(size)\n",
      "File \u001b[1;32mc:\\Users\\Kelvin\\anaconda3\\envs\\fastAI\\lib\\gzip.py:479\u001b[0m, in \u001b[0;36m_GzipReader.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    475\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_new_member:\n\u001b[0;32m    476\u001b[0m     \u001b[39m# If the _new_member flag is set, we have to\u001b[39;00m\n\u001b[0;32m    477\u001b[0m     \u001b[39m# jump to the next member, if there is one.\u001b[39;00m\n\u001b[0;32m    478\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_read()\n\u001b[1;32m--> 479\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_gzip_header():\n\u001b[0;32m    480\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pos\n\u001b[0;32m    481\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Kelvin\\anaconda3\\envs\\fastAI\\lib\\gzip.py:427\u001b[0m, in \u001b[0;36m_GzipReader._read_gzip_header\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    424\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[39mif\u001b[39;00m magic \u001b[39m!=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\037\u001b[39;00m\u001b[39m\\213\u001b[39;00m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 427\u001b[0m     \u001b[39mraise\u001b[39;00m BadGzipFile(\u001b[39m'\u001b[39m\u001b[39mNot a gzipped file (\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m magic)\n\u001b[0;32m    429\u001b[0m (method, flag,\n\u001b[0;32m    430\u001b[0m  \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_last_mtime) \u001b[39m=\u001b[39m struct\u001b[39m.\u001b[39munpack(\u001b[39m\"\u001b[39m\u001b[39m<BBIxx\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_read_exact(\u001b[39m8\u001b[39m))\n\u001b[0;32m    431\u001b[0m \u001b[39mif\u001b[39;00m method \u001b[39m!=\u001b[39m \u001b[39m8\u001b[39m:\n",
      "\u001b[1;31mBadGzipFile\u001b[0m: Not a gzipped file (b'te')"
     ]
    }
   ],
   "source": [
    "tmp = parse(fetch(\"test\"))[0x8:]\n",
    "print(tmp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    import gzip\n",
    "    import numpy as np\n",
    "\n",
    "    X_train = parse(fetch(url1))[0x10:].reshape((-1, 28, 28))\n",
    "    Y_train = parse(fetch(url2))[8:]\n",
    "    X_test = parse(fetch(url3))[0x10:].reshape((-1, 28, 28))\n",
    "    Y_test = parse(fetch(url4))[8:]\n",
    "    return X_train, Y_train, X_test, Y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read file directly here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can use the local files directly\n",
    "#### Or, use wget command / fetch() function + pickle module to load the data into the buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd # to process csv files more conveniently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# use pandas to process training.csv here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text,label\n",
      " <class 'str'> text,label\n",
      "\n",
      "i didnt feel humiliated,0\n",
      " <class 'str'> i didnt feel humiliated,0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#export\n",
    "# we should abandon this and just use pandas instead ?\n",
    "def get_train_set():\n",
    "    with open(\"training.csv\", 'r') as f:\n",
    "        cnt = 0\n",
    "        for line in f:\n",
    "            print(line, type(line), line.rstrip(','))\n",
    "            cnt += 1\n",
    "            if cnt == 2:\n",
    "                break\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_train_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build the model (via tensorflow first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "starting from the easiest one (for demo & proceding work)\n",
    ": lstm -> lstm -> dense -> sigmoid -> output ? // arbitrary proposed\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import tensorflow\n",
    "def build_model():\n",
    "    model = [blah ...]\n",
    "    model.summary() # probably not gonna work, stupid static graph\n",
    "model.compile()\n",
    "hist = model.fit()\n",
    "plotit(hist)\n",
    "...\n",
    "model.save(weight_name)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('AI_sheng')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "9db77c7d38baf4b93e998a2213b9026a3d1545f748ab5419893b25caa4e3cb58"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
