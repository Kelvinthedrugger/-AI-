{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp model_api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKRrSAEnojUe"
   },
   "source": [
    "# We are in dev branch so it's fine\n",
    "### On dev branch:\n",
    "###     dig into tokenized input shape\n",
    "###     check if we need to reshape/unsqueeze input for inference only\n",
    "###     don't merge this until it works\n",
    "###     probably dev on local end tho it'll takes disc space\n",
    "# run line by line instead of \"execute all\" button\n",
    "### Don't just directly re-run this notebook\n",
    "### But to copy it first\n",
    "### Running on google colab is highly recommended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eexYGlh1qCWH"
   },
   "source": [
    "## To load weight, see the saved weight inside my cloud\n",
    "## note that !wget URLs for \"model.pt\" doesn't work\n",
    "## presumably needs to unzip the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E3W9Ps2aUFA-"
   },
   "source": [
    "## My personal note\n",
    "### torch_lr_finder: import error, which is dumb\n",
    "\n",
    "\n",
    "### Suggestion:\n",
    "#### We should try fast ai if time permits, but it's not our main goal\n",
    "\n",
    "## ---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wj6eoKzotv5I"
   },
   "source": [
    "## Emotion Classification using Fine-tuned BERT model\n",
    "\n",
    "In this tutorial, I will show to fine-tune a language model (LM) for emotion classification with code adapted from this [tutorial](https://zablo.net/blog/post/custom-classifier-on-bert-model-guide-polemo2-sentiment-analysis/) by MARCIN ZABŁOCKI. I adapted his tutorial and modified the code to suit the emotion classification task using a different BERT model. Please refer to his tutorial for more detailed explanations for each code block. I really liked his tutorial because of the attention to detail and the use of high-level libraries to take care of certain parts of the model such as training and finding a good learning rate. \n",
    "\n",
    "Before you get started, make sure to enable `GPU` in the runtime and be sure to \n",
    "restart the runtime in this environment after installing the `pytorch-lr-finder` library.\n",
    "\n",
    "This tutorial is in a rough draft so if you find any issues with this tutorial or have any further questions reach out to me via [Twitter](https://twitter.com/omarsar0). \n",
    "\n",
    "Note that the notebook was created a little while back so if something break it's because the code is not compatible with the library changes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### skip these dependency shxt since we should've done it when setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "G2tokZqttmTA"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install transformers tokenizers pytorch-lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I0jZnNegGhZj"
   },
   "source": [
    "Note: you need to Restart runtime after running this code segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "k9ZKIIGvuW5m"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!git clone https://github.com/davidtvs/pytorch-lr-finder.git && cd pytorch-lr-finder && python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "qqRRWe4UuuIh",
    "outputId": "52ca4c41-d22e-40d1-b05a-5526d7d29347"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'1.11.0+cu113'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from typing import List\n",
    "import torch.nn.functional as F\n",
    "from transformers import DistilBertTokenizer, AutoTokenizer, AutoModelWithLMHead, DistilBertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "import logging\n",
    "import os\n",
    "from functools import lru_cache\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "from tokenizers.processors import BertProcessing\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "from argparse import Namespace\n",
    "from sklearn.metrics import classification_report\n",
    "# torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_whSBDujRiga"
   },
   "source": [
    "## Load the Pretrained Language Model\n",
    "We are first going to look at pretrained language model provided by HuggingFace models. We will use a variant of BERT, called DistilRoBERTa base. The `base` model has less parameters than the `larger` model. \n",
    "\n",
    "[RoBERTa](https://arxiv.org/abs/1907.11692) is a variant of of BERT which \"*modifies key hyperparameters, removing the next-sentence pretraining objective and training with much larger mini-batches and learning rates*\".\n",
    "\n",
    "Knowledge distillation help to train smaller LMs with similar performance and potential."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BvHNcMckSR4M"
   },
   "source": [
    "First, let's load the tokenizer for this model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "419c3cb65daa4068894430fe02a0fdbf",
      "1e26029c0b394dc0a8e2aa24eb3b563d",
      "7ac1ef8a96ca4ffa98b84c0146b05b3a",
      "e1fd29ec64d844cf8a336e8dc4b56d16",
      "c4f2a52e0bea43b7abdba2e4fda1e046",
      "1dd352a1a5764185b3070bec03b1eed1",
      "226e92a0d27f407784a84cff66fdd5bb",
      "e6a7e7cbc424407c9f59ab2afa2a4a8e",
      "9198556f3251499094563166fde76b11",
      "f505b2bc24cb4c1ca73d41ea317be6a6",
      "ac6568c65a774f57b4c05d1f05147434",
      "89698711961f415d8891362453273919",
      "2ac61322048848d19ceae50bd23e783a",
      "e8623d85e14741f0be0f41edcbde2fde",
      "f8f5ff97a69442039ad481db4cc9dcb8",
      "fdb737a550b7446ab61b85ad0e7d15e9",
      "d2e210040cba466590a57f14dc463deb",
      "346aa2f0c3324c8a8ea3e54370b6004a",
      "e5d7192438aa4097aa75f0dcf000bacb",
      "5ee53b7b6fc34e2dbc8d0fe3346af00c",
      "c8ea6b01fbf54f78b2707802b9f7807b",
      "50f4185d84c442858bc270dccd3f0190",
      "0a889fbe6d58487cb250e18c1e4e9907",
      "3c4d2966c20b41f891bf4d2786ad9bce",
      "fc3bdaecaaf34c2a87dbf888c7d6276f",
      "18f13adddb904b72a713555453af20f4",
      "3c6d2d4247de4426ab952770d58fe11a",
      "0d7c6e994a7e4b6aba2a475ced08c87c",
      "489efd83a5324299afed67e7c8cd642f",
      "cebed77f95584d1884bb16d961651913",
      "e5a82d4b2b8a4b25a55650979a822eb8",
      "f68bc923635046b09f8f864f90221b79",
      "8b2a46ebb9f74408898e120289efe571",
      "b6eabc4f212d494aaf611d6b17d8b1b1",
      "abf15a0b598f4fb18112d2311b62eeb2",
      "d19f9c4760a540e9a263bdfac7dcf38c",
      "eb36d0c9c3d246b49b43548261fa6390",
      "9a17f0749f4c4b71937971309023ed7b",
      "b7c5e2f903b143da9638be238dd734ff",
      "ceabcaf7af35477f92c419af41e78e40",
      "4f784f40b2c6470e9b4663448333e308",
      "e5dbc0014c2047f688d05b07cd814abc",
      "699dd771419c4f1392b9725aec5f4c9e",
      "de9a0fd1bd2b4af792c6786b9bf29e33"
     ]
    },
    "id": "BPbTd5lmuzQn",
    "outputId": "8831f5fd-237f-4793-c344-ec726992870e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "419c3cb65daa4068894430fe02a0fdbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89698711961f415d8891362453273919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a889fbe6d58487cb250e18c1e4e9907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6eabc4f212d494aaf611d6b17d8b1b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('distilroberta-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7KAbKMqJSWRo"
   },
   "source": [
    "Now let's load the actual model with the LM head that takes care of the prediciton for the LM. When fine-tuning we don't use the head and instead use the base model. The code below shows how to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104,
     "referenced_widgets": [
      "74eb6e5637ee4611b6f4b9a2a14e620e",
      "0a24cf351cd6416b96998cf2f5da2512",
      "c4ce1e4457d6438093cc83dc1f3f143f",
      "cb473ac8713d4066b8fd7aa03a1c429d",
      "7bbb1627a28640549737062b3d979a6c",
      "b3a93724ad3d4fd48a5471af0f0400af",
      "62c6c07e96e649df8c22514a8689009e",
      "55aa8b496bdb4e2c89037ed3a9416c33",
      "711ce4c4c7ea47e8a374f710e4d0e59a",
      "47452bb290fb462da0444aa57585f840",
      "27d620c696774566a9147b6543631cdc"
     ]
    },
    "id": "PCXYlMydzQlP",
    "outputId": "ba361129-9718-48b0-be47-0f9b4bd59beb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/models/auto/modeling_auto.py:973: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74eb6e5637ee4611b6f4b9a2a14e620e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/316M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelWithLMHead.from_pretrained(\"distilroberta-base\")\n",
    "base_model = model.base_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K2_8S8BXSpNa"
   },
   "source": [
    "Let's now try out the tokenizer first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5fidSmH-zrY_",
    "outputId": "52c77ba0-3927-4d6c-8495-f5bf0f8a658b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Elvis is the king of rock!\"\n",
    "enc = tokenizer.encode_plus(text)\n",
    "enc.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m8F8yQCDTDQi",
    "outputId": "1fc63e7d-98e4-46e9-f0b6-9c090a3f5b55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [0, 9682, 9578, 16, 5, 8453, 9, 3152, 328, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "print(enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3wSCLKW0ndh"
   },
   "source": [
    "`input_ids` are the numerical encoding of the tokens in the vocabulary. `attention_mask` is an addition option used when batching sequences together and you want to tell the model which tokens should be attented to ([read more](https://huggingface.co/transformers/glossary.html#attention-mask)). The attention mask information helps when dealing with variance in the size of sequences and we need a way to tell the model that we don't want to attend to the padded indices of the sequence.\n",
    "\n",
    "We are only using `input_ids` and `attention_mask`\n",
    "\n",
    "We need to also unsqueeze to simulate batch processing\n",
    "\n",
    "Using DistilBertForSequenceClassification: https://huggingface.co/transformers/model_doc/distilbert.html#distilbertforsequenceclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mxsts4uT0PgA",
    "outputId": "15a4c9b6-72d0-43cb-b9f3-e22c513f9e80"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 768])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = base_model(torch.tensor(enc[\"input_ids\"]).unsqueeze(0), torch.tensor(enc[\"attention_mask\"]).unsqueeze(0))\n",
    "out[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZiCO-n_1AHIf",
    "outputId": "cb563585-db85-45ae-8546-db3673868aa1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## size of representation of one of the tokens \n",
    "out[0][:,0,:].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "srwIb9nr4g4t"
   },
   "source": [
    "`torch.Size([1, 768])` represents batch_size, number of tokens in input text (lenght of tokenized text), model's output hidden size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iAsg0H6g53Bf",
    "outputId": "7afcd4fb-9f96-4734-9f53-5583fa9a59e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 9682, 9578, 16, 5, 8453, 9, 3152, 2]\n",
      "<s>Elvis is the king of rock</s>\n",
      "Length: 9\n",
      "torch.Size([9, 768])\n"
     ]
    }
   ],
   "source": [
    "t = \"Elvis is the king of rock\"\n",
    "enc = tokenizer.encode_plus(t)\n",
    "token_representations = base_model(torch.tensor(enc[\"input_ids\"]).unsqueeze(0))[0][0]\n",
    "print(enc[\"input_ids\"])\n",
    "print(tokenizer.decode(enc[\"input_ids\"]))\n",
    "print(f\"Length: {len(enc['input_ids'])}\")\n",
    "print(token_representations.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9RFifOoY7Hsc"
   },
   "source": [
    "## Building Custom Classification head on top of LM base model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vSUMm4Oq7nvR"
   },
   "source": [
    "Use Mish activiation function as in the one proposed in the original tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "tCEDXLxq628O"
   },
   "outputs": [],
   "source": [
    "# from https://github.com/digantamisra98/Mish/blob/b5f006660ac0b4c46e2c6958ad0301d7f9c59651/Mish/Torch/mish.py\n",
    "@torch.jit.script\n",
    "def mish(input):\n",
    "    import torch.nn.functional as F\n",
    "    return input * torch.tanh(F.softplus(input))\n",
    "\n",
    "class Mish(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return mish(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6Ln6KWm74ku"
   },
   "source": [
    "The model we will use to do the fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "9VDRSRsc71H2"
   },
   "outputs": [],
   "source": [
    "class EmoModel(nn.Module):\n",
    "    def __init__(self, base_model, n_classes, base_model_output_size=768, dropout=0.05):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(base_model_output_size, base_model_output_size),\n",
    "            Mish(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(base_model_output_size, n_classes)\n",
    "        )\n",
    "\n",
    "        for layer in self.classifier:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                layer.weight.data.normal_(mean=0.0, std=0.02)\n",
    "                if layer.bias is not None:\n",
    "                    layer.bias.data.zero_()\n",
    "\n",
    "    def forward(self, input_, *args):\n",
    "        X, attention_mask = input_\n",
    "        hidden_states = self.base_model(X, attention_mask=attention_mask)\n",
    "\n",
    "        # maybe do some pooling / RNNs... go crazy here!\n",
    "\n",
    "        # use the <s> representation\n",
    "        return self.classifier(hidden_states[0][:, 0, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wjgME-3O8Yfo"
   },
   "source": [
    "### Pretest the model with dummy text\n",
    "We want to ensure that the model is returing the right information back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y6H9eF8A8XeV",
    "outputId": "1e26fa71-98ad-4efb-f46d-eb1c88d8293f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/models/auto/modeling_auto.py:973: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "classifier = EmoModel(AutoModelWithLMHead.from_pretrained(\"distilroberta-base\").base_model, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "-sjfHJ_L9iNH"
   },
   "outputs": [],
   "source": [
    "X = torch.tensor(enc[\"input_ids\"]).unsqueeze(0).to('cpu')\n",
    "attn = torch.tensor(enc[\"attention_mask\"]).unsqueeze(0).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o6QhCuEC-y2z",
    "outputId": "8853d73d-763b-4b8b-dfd5-75e90f953ca3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1105,  0.2375, -0.1072]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier((X, attn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I-N7WSY7Cb7v"
   },
   "source": [
    "## Prepare your dataset for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "jDWkjaLV-5tj"
   },
   "outputs": [],
   "source": [
    "!mkdir -p tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wMMm5Ye1Db-m",
    "outputId": "a883b305-c69b-464a-b307-3ef22e47f572"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tokenizer/tokenizer_config.json',\n",
       " 'tokenizer/special_tokens_map.json',\n",
       " 'tokenizer/vocab.json',\n",
       " 'tokenizer/merges.txt',\n",
       " 'tokenizer/added_tokens.json',\n",
       " 'tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## load pretrained tokenizer information\n",
    "tokenizer.save_pretrained(\"tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3FVtbmrzDkF8",
    "outputId": "f882d65a-27a1-4984-81fa-1ba779cbebc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merges.txt\t\t tokenizer_config.json\tvocab.json\n",
      "special_tokens_map.json  tokenizer.json\n"
     ]
    }
   ],
   "source": [
    "!ls tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BhTEgIaLEDRo"
   },
   "source": [
    "Implement CollateFN using fast tokenizers.\n",
    "This function basically takes care of proper tokenization and batches of sequences. This way you don't need to create your batches manually. Find out more about Tokenizers [here](https://github.com/huggingface/tokenizers/tree/master/bindings/python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "3SCLBZsMDn4s"
   },
   "outputs": [],
   "source": [
    "# needed for tokenize the user input\n",
    "class TokenizersCollateFn:\n",
    "    def __init__(self, max_tokens=512):\n",
    "\n",
    "        # I still need this to parse the input\n",
    "        # try to figure out where to store these tokens\n",
    "        # instead of re-download it every time\n",
    "        # reload is probably fine if the model is on AWS?\n",
    "        ## RoBERTa uses BPE tokenizer similar to GPT\n",
    "        t = ByteLevelBPETokenizer(\n",
    "            \"tokenizer/vocab.json\",\n",
    "            \"tokenizer/merges.txt\"\n",
    "        )\n",
    "        t._tokenizer.post_processor = BertProcessing(\n",
    "            (\"</s>\", t.token_to_id(\"</s>\")),\n",
    "            (\"<s>\", t.token_to_id(\"<s>\")),\n",
    "        )\n",
    "        t.enable_truncation(max_tokens)\n",
    "        t.enable_padding(length=max_tokens, pad_id=t.token_to_id(\"<pad>\"))\n",
    "        self.tokenizer = t\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        encoded = self.tokenizer.encode_batch([x[0] for x in batch])\n",
    "        sequences_padded = torch.tensor([enc.ids for enc in encoded])\n",
    "        attention_masks_padded = torch.tensor([enc.attention_mask for enc in encoded])\n",
    "        labels = torch.tensor([x[1] for x in batch])\n",
    "        \n",
    "        return (sequences_padded, attention_masks_padded), labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4hu70Ng0Eqls"
   },
   "source": [
    "## Getting the Data and Preview it\n",
    "Below we are going to load the data and show you how to create the splits. However, we don't need to split the data manually becuase I have already created the splits and stored those files seperately which you can quickly download below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JZ3SoJH3fUsq",
    "outputId": "e0ebe7a4-9223-4e0e-c582-338d3422930d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-07-04 12:51:43--  https://www.dropbox.com/s/ikkqxfdbdec3fuj/test.txt\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.4.18, 2620:100:6019:18::a27d:412\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.4.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/ikkqxfdbdec3fuj/test.txt [following]\n",
      "--2022-07-04 12:51:43--  https://www.dropbox.com/s/raw/ikkqxfdbdec3fuj/test.txt\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://ucbaec52c9833bf780517d882e40.dl.dropboxusercontent.com/cd/0/inline/BoZN5Yhoh4odNGswTqol1TyJvJds0cGZJ9yCO7e_SSKoDQQHx0nGoN_RdA9eK67l3PeuntcfZsX8KXqZoBEppu28WtaRFrOtxH-93B1jkcr_2EiLwsftygxqHRXg2pRXZ_FrchY4gEo_eeLulOzD43_xh9k7kdBLZJr4_sbnNaMBxg/file# [following]\n",
      "--2022-07-04 12:51:43--  https://ucbaec52c9833bf780517d882e40.dl.dropboxusercontent.com/cd/0/inline/BoZN5Yhoh4odNGswTqol1TyJvJds0cGZJ9yCO7e_SSKoDQQHx0nGoN_RdA9eK67l3PeuntcfZsX8KXqZoBEppu28WtaRFrOtxH-93B1jkcr_2EiLwsftygxqHRXg2pRXZ_FrchY4gEo_eeLulOzD43_xh9k7kdBLZJr4_sbnNaMBxg/file\n",
      "Resolving ucbaec52c9833bf780517d882e40.dl.dropboxusercontent.com (ucbaec52c9833bf780517d882e40.dl.dropboxusercontent.com)... 162.125.6.15, 2620:100:6019:15::a27d:40f\n",
      "Connecting to ucbaec52c9833bf780517d882e40.dl.dropboxusercontent.com (ucbaec52c9833bf780517d882e40.dl.dropboxusercontent.com)|162.125.6.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 206760 (202K) [text/plain]\n",
      "Saving to: ‘test.txt’\n",
      "\n",
      "test.txt            100%[===================>] 201.91K  --.-KB/s    in 0.06s   \n",
      "\n",
      "2022-07-04 12:51:44 (3.55 MB/s) - ‘test.txt’ saved [206760/206760]\n",
      "\n",
      "--2022-07-04 12:51:44--  https://www.dropbox.com/s/1pzkadrvffbqw6o/train.txt\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.4.18, 2620:100:6019:18::a27d:412\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.4.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/1pzkadrvffbqw6o/train.txt [following]\n",
      "--2022-07-04 12:51:44--  https://www.dropbox.com/s/raw/1pzkadrvffbqw6o/train.txt\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc51396343f06df4657f9c8d6aae.dl.dropboxusercontent.com/cd/0/inline/BoZfCU-qFL4O272wpMceYJp6j6MmkFri44MaNgHq_8__o5fAk3qi5T3ldqvOwkoX1kF0L6xvZQ1nUOeNMWuG98nHrrfTF7bxZI_4VP2KdYHzRN5TErmbvcPDoGBViht2NB6bG3dBpd7WGV3HcJ2YWjPInkGY9dFf-TrHPtG13tJ4Pw/file# [following]\n",
      "--2022-07-04 12:51:45--  https://uc51396343f06df4657f9c8d6aae.dl.dropboxusercontent.com/cd/0/inline/BoZfCU-qFL4O272wpMceYJp6j6MmkFri44MaNgHq_8__o5fAk3qi5T3ldqvOwkoX1kF0L6xvZQ1nUOeNMWuG98nHrrfTF7bxZI_4VP2KdYHzRN5TErmbvcPDoGBViht2NB6bG3dBpd7WGV3HcJ2YWjPInkGY9dFf-TrHPtG13tJ4Pw/file\n",
      "Resolving uc51396343f06df4657f9c8d6aae.dl.dropboxusercontent.com (uc51396343f06df4657f9c8d6aae.dl.dropboxusercontent.com)... 162.125.6.15, 2620:100:6019:15::a27d:40f\n",
      "Connecting to uc51396343f06df4657f9c8d6aae.dl.dropboxusercontent.com (uc51396343f06df4657f9c8d6aae.dl.dropboxusercontent.com)|162.125.6.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1658616 (1.6M) [text/plain]\n",
      "Saving to: ‘train.txt’\n",
      "\n",
      "train.txt           100%[===================>]   1.58M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2022-07-04 12:51:45 (14.7 MB/s) - ‘train.txt’ saved [1658616/1658616]\n",
      "\n",
      "--2022-07-04 12:51:45--  https://www.dropbox.com/s/2mzialpsgf9k5l3/val.txt\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.4.18, 2620:100:6019:18::a27d:412\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.4.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/2mzialpsgf9k5l3/val.txt [following]\n",
      "--2022-07-04 12:51:46--  https://www.dropbox.com/s/raw/2mzialpsgf9k5l3/val.txt\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://ucff127704c4ae68dba2c9549db3.dl.dropboxusercontent.com/cd/0/inline/BoazdkJImC4ykbNVmH67WS71XHt2qV-D4BI3xTwkahetGZRpEB3RhjhO389hRSEHfKgFi07DwAjlBq1dSvoFNJV7IwLviHTI_vLKFDpocIwKtZninyW7VlBEu8xw2B0G33tDWZVEo4GarVvUqrY5TzvrJoJ0md-TW6_t7lIfr6ibyA/file# [following]\n",
      "--2022-07-04 12:51:46--  https://ucff127704c4ae68dba2c9549db3.dl.dropboxusercontent.com/cd/0/inline/BoazdkJImC4ykbNVmH67WS71XHt2qV-D4BI3xTwkahetGZRpEB3RhjhO389hRSEHfKgFi07DwAjlBq1dSvoFNJV7IwLviHTI_vLKFDpocIwKtZninyW7VlBEu8xw2B0G33tDWZVEo4GarVvUqrY5TzvrJoJ0md-TW6_t7lIfr6ibyA/file\n",
      "Resolving ucff127704c4ae68dba2c9549db3.dl.dropboxusercontent.com (ucff127704c4ae68dba2c9549db3.dl.dropboxusercontent.com)... 162.125.6.15, 2620:100:6019:15::a27d:40f\n",
      "Connecting to ucff127704c4ae68dba2c9549db3.dl.dropboxusercontent.com (ucff127704c4ae68dba2c9549db3.dl.dropboxusercontent.com)|162.125.6.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 204240 (199K) [text/plain]\n",
      "Saving to: ‘val.txt’\n",
      "\n",
      "val.txt             100%[===================>] 199.45K  --.-KB/s    in 0.06s   \n",
      "\n",
      "2022-07-04 12:51:47 (3.53 MB/s) - ‘val.txt’ saved [204240/204240]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.dropbox.com/s/ikkqxfdbdec3fuj/test.txt\n",
    "!wget https://www.dropbox.com/s/1pzkadrvffbqw6o/train.txt\n",
    "!wget https://www.dropbox.com/s/2mzialpsgf9k5l3/val.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "r_03fxufWX_G"
   },
   "outputs": [],
   "source": [
    "## export the datasets as txt files\n",
    "## EXERCISE: Change this to an address\n",
    "\n",
    "train_path = \"train.txt\"\n",
    "test_path = \"test.txt\"\n",
    "val_path = \"val.txt\"\n",
    "\n",
    "## emotion labels\n",
    "label2int = {\n",
    "  \"sadness\": 0,\n",
    "  \"joy\": 1,\n",
    "  \"love\": 2,\n",
    "  \"anger\": 3,\n",
    "  \"fear\": 4,\n",
    "  \"surprise\": 5\n",
    "}\n",
    "\n",
    "emotions = [ \"sadness\", \"joy\", \"love\", \"anger\", \"fear\", \"surprise\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-FJ-wN1_zmkV"
   },
   "source": [
    "### A Quick Look at the dataset\n",
    "Below is a few code sniphets to get a good idea of the dataset we are using here. You can skip this whole subsection if you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t23zHggkEpc-",
    "outputId": "b22769e0-ef60-4a50-f00a-ba8112420d09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-07-04 12:51:47--  https://www.dropbox.com/s/607ptdakxuh5i4s/merged_training.pkl\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.4.18, 2620:100:6019:18::a27d:412\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.4.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/607ptdakxuh5i4s/merged_training.pkl [following]\n",
      "--2022-07-04 12:51:47--  https://www.dropbox.com/s/raw/607ptdakxuh5i4s/merged_training.pkl\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc615c650bddae1f31315dbe01be.dl.dropboxusercontent.com/cd/0/inline/BoagSRMtLxoafwVPfktiUwWXyPv1txKcLgIQtcfekgRGSvIvDBDFdctfIdLWCtunrOCho3rkNJlJhmpwMM8GgveZkygqHr_2Ytl0EbFpB1APVPuDpNdBYvS2ymoqBKLvuia8VDeK1F5vgaEs2n1_o-qjKgeds8LCSPTwbkN5gwFgNA/file# [following]\n",
      "--2022-07-04 12:51:47--  https://uc615c650bddae1f31315dbe01be.dl.dropboxusercontent.com/cd/0/inline/BoagSRMtLxoafwVPfktiUwWXyPv1txKcLgIQtcfekgRGSvIvDBDFdctfIdLWCtunrOCho3rkNJlJhmpwMM8GgveZkygqHr_2Ytl0EbFpB1APVPuDpNdBYvS2ymoqBKLvuia8VDeK1F5vgaEs2n1_o-qjKgeds8LCSPTwbkN5gwFgNA/file\n",
      "Resolving uc615c650bddae1f31315dbe01be.dl.dropboxusercontent.com (uc615c650bddae1f31315dbe01be.dl.dropboxusercontent.com)... 162.125.4.15, 2620:100:6019:15::a27d:40f\n",
      "Connecting to uc615c650bddae1f31315dbe01be.dl.dropboxusercontent.com (uc615c650bddae1f31315dbe01be.dl.dropboxusercontent.com)|162.125.4.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: /cd/0/inline2/BoYQ-QiaVYsJX3HieVJ4nZJG3Ji4RacJHDO1sqP6jn0ArlQN0-SM5PO8L88eW9doWEr1KyG2I68RI1sXd6N7MfF-8atNLzoOn_7iMIrNmW47swZGtIX51IMTgljubPjss7qOhznCojRHMxW5DTlG_UXiOgvtMLVosMda1pY74-ATcgiS2cbsObhSGX7w3o9qi7Vbt0O5iReMFQhMPK44SAMgWgRDGoF_aQw3ewz25qMXq6-rfEb17a6g98vADJCtQf_d1aU-xQ093-AEfj4CPbal2HDFFBS00m1rVxaEk_hb971b_ITr-MpRHf_cdYbcWHfET9Ep3jB4taI7EIf9XEUyU8H5JofBzcxeNefmxSpVENFjyDzvbtwpr4cOMCpGVFeR6VMlkHXuZtnRcg5ZVlXQSj1OVmzg373vPmcvsKJSfw/file [following]\n",
      "--2022-07-04 12:51:48--  https://uc615c650bddae1f31315dbe01be.dl.dropboxusercontent.com/cd/0/inline2/BoYQ-QiaVYsJX3HieVJ4nZJG3Ji4RacJHDO1sqP6jn0ArlQN0-SM5PO8L88eW9doWEr1KyG2I68RI1sXd6N7MfF-8atNLzoOn_7iMIrNmW47swZGtIX51IMTgljubPjss7qOhznCojRHMxW5DTlG_UXiOgvtMLVosMda1pY74-ATcgiS2cbsObhSGX7w3o9qi7Vbt0O5iReMFQhMPK44SAMgWgRDGoF_aQw3ewz25qMXq6-rfEb17a6g98vADJCtQf_d1aU-xQ093-AEfj4CPbal2HDFFBS00m1rVxaEk_hb971b_ITr-MpRHf_cdYbcWHfET9Ep3jB4taI7EIf9XEUyU8H5JofBzcxeNefmxSpVENFjyDzvbtwpr4cOMCpGVFeR6VMlkHXuZtnRcg5ZVlXQSj1OVmzg373vPmcvsKJSfw/file\n",
      "Reusing existing connection to uc615c650bddae1f31315dbe01be.dl.dropboxusercontent.com:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 49991846 (48M) [application/octet-stream]\n",
      "Saving to: ‘merged_training.pkl’\n",
      "\n",
      "merged_training.pkl 100%[===================>]  47.68M  60.6MB/s    in 0.8s    \n",
      "\n",
      "2022-07-04 12:51:49 (60.6 MB/s) - ‘merged_training.pkl’ saved [49991846/49991846]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.dropbox.com/s/607ptdakxuh5i4s/merged_training.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "PQrMSUTRF06B"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "## helper function\n",
    "def load_from_pickle(directory):\n",
    "    return pickle.load(open(directory,\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "XGz89mNSHaYM",
    "outputId": "fb6c4269-1c20-476c-fb87-e0aa5c6d90a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f88f0bb9590>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = load_from_pickle(directory=\"merged_training.pkl\")\n",
    "\n",
    "## using a sample\n",
    "data= data[data[\"emotions\"].isin(emotions)]\n",
    "\n",
    "\n",
    "data = data.sample(n=20000);\n",
    "\n",
    "data.emotions.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Comaf36-Hb6X",
    "outputId": "2e94db84-0434-48d8-8596-283ff899eccc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text        20000\n",
       "emotions    20000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYxc8fx_H3ad"
   },
   "source": [
    "Data has been preprocessed already, using technique from this paper: https://www.aclweb.org/anthology/D18-1404/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "gYKK7ujRHfRt",
    "outputId": "ab5ca66e-e37e-4bc9-be64-67076ba11b32"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-0ef19032-e640-4f44-9aa8-a5a5ed005f07\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54470</th>\n",
       "      <td>i feel most relieved</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51736</th>\n",
       "      <td>ill talk to most anyone as long as im not feel...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49002</th>\n",
       "      <td>i feel rather listless and floppy and really o...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18208</th>\n",
       "      <td>i climbed up on that tank feeling like i belon...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85461</th>\n",
       "      <td>i read from a site stating that if we feel lon...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ef19032-e640-4f44-9aa8-a5a5ed005f07')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-0ef19032-e640-4f44-9aa8-a5a5ed005f07 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-0ef19032-e640-4f44-9aa8-a5a5ed005f07');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                    text emotions\n",
       "54470                               i feel most relieved      joy\n",
       "51736  ill talk to most anyone as long as im not feel...    anger\n",
       "49002  i feel rather listless and floppy and really o...  sadness\n",
       "18208  i climbed up on that tank feeling like i belon...      joy\n",
       "85461  i read from a site stating that if we feel lon...  sadness"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "JXovcl56NFPp"
   },
   "outputs": [],
   "source": [
    "## reset index\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pSzoz9InH0Ta",
    "outputId": "0248af11-fc58-41a5-bddb-aca2dd4c528c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['joy', 'anger', 'sadness', 'fear', 'surprise', 'love'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check unique emotions in the dataset\n",
    "data.emotions.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rJm31gKShQus"
   },
   "source": [
    "## Split the data and store into individual text files\n",
    "\n",
    "If you are using your own dataset and want to split it for training, you can uncomment the code below. Otherwise, just skip it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 157
    },
    "id": "6ooNxSnPiztL",
    "outputId": "4a9179c6-2788-4c27-c145-2d3e7e18e8ae"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\nfrom sklearn.model_selection import train_test_split\\nimport numpy as np\\n\\n# Creating training and validation sets using an 80-20 split\\ninput_train, input_val, target_train, target_val = train_test_split(data.text.to_numpy(), \\n                                                                    data.emotions.to_numpy(), \\n                                                                    test_size=0.2)\\n\\n# Split the validataion further to obtain a holdout dataset (for testing) -- split 50:50\\ninput_val, input_test, target_val, target_test = train_test_split(input_val, target_val, test_size=0.5)\\n\\n\\n## create a dataframe for each dataset\\ntrain_dataset = pd.DataFrame(data={\"text\": input_train, \"class\": target_train})\\nval_dataset = pd.DataFrame(data={\"text\": input_val, \"class\": target_val})\\ntest_dataset = pd.DataFrame(data={\"text\": input_test, \"class\": target_test})\\nfinal_dataset = {\"train\": train_dataset, \"val\": val_dataset , \"test\": test_dataset }\\n\\ntrain_dataset.to_csv(train_path, sep=\";\",header=False, index=False)\\nval_dataset.to_csv(test_path, sep=\";\",header=False, index=False)\\ntest_dataset.to_csv(val_path, sep=\";\",header=False, index=False)\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## uncomment the code below to generate the text files for your train, val, and test datasets.\n",
    "\n",
    "'''\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Creating training and validation sets using an 80-20 split\n",
    "input_train, input_val, target_train, target_val = train_test_split(data.text.to_numpy(), \n",
    "                                                                    data.emotions.to_numpy(), \n",
    "                                                                    test_size=0.2)\n",
    "\n",
    "# Split the validataion further to obtain a holdout dataset (for testing) -- split 50:50\n",
    "input_val, input_test, target_val, target_test = train_test_split(input_val, target_val, test_size=0.5)\n",
    "\n",
    "\n",
    "## create a dataframe for each dataset\n",
    "train_dataset = pd.DataFrame(data={\"text\": input_train, \"class\": target_train})\n",
    "val_dataset = pd.DataFrame(data={\"text\": input_val, \"class\": target_val})\n",
    "test_dataset = pd.DataFrame(data={\"text\": input_test, \"class\": target_test})\n",
    "final_dataset = {\"train\": train_dataset, \"val\": val_dataset , \"test\": test_dataset }\n",
    "\n",
    "train_dataset.to_csv(train_path, sep=\";\",header=False, index=False)\n",
    "val_dataset.to_csv(test_path, sep=\";\",header=False, index=False)\n",
    "test_dataset.to_csv(val_path, sep=\";\",header=False, index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rAD1J6c0dLp8"
   },
   "source": [
    "## Create the Dataset object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aOOI69vwIYcN"
   },
   "source": [
    "Create the Dataset object that will be used to load the different datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Ktr6xeMuISin"
   },
   "outputs": [],
   "source": [
    "class EmoDataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        super().__init__()\n",
    "        self.data_column = \"text\"\n",
    "        self.class_column = \"class\"\n",
    "        self.data = pd.read_csv(path, sep=\";\", header=None, names=[self.data_column, self.class_column],\n",
    "                               engine=\"python\")\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data.loc[idx, self.data_column], label2int[self.data.loc[idx, self.class_column]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9EYQRq3qJH7n"
   },
   "source": [
    "Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uGWw4wGEJGhJ",
    "outputId": "f9c63db5-d63b-4b91-f020-bb3230213671"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('i now feel compromised and skeptical of the value of every unit of work i put in',\n",
       " 4)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = EmoDataset(train_path)\n",
    "ds[19]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0h6tTn9hd6v8"
   },
   "source": [
    "## Training with PyTorchLightning\n",
    "\n",
    "[PyTorchLightning](https://www.pytorchlightning.ai/) is a library that abstracts the complexity of training neural networks with PyTorch. It is built on top of PyTorch and simplifies training.\n",
    "\n",
    "![](https://pytorch-lightning.readthedocs.io/en/latest/_images/pt_to_pl.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "RJHhNRcZK7sV"
   },
   "outputs": [],
   "source": [
    "## Methods required by PyTorchLightning\n",
    "\n",
    "class TrainingModule(pl.LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        self.model = EmoModel(AutoModelWithLMHead.from_pretrained(\"distilroberta-base\").base_model, len(emotions))\n",
    "        self.loss = nn.CrossEntropyLoss() ## combines LogSoftmax() and NLLLoss()\n",
    "        #self.hparams = hparams\n",
    "        self.hparams.update(vars(hparams))\n",
    "\n",
    "    def step(self, batch, step_name=\"train\"):\n",
    "        X, y = batch\n",
    "        loss = self.loss(self.forward(X), y)\n",
    "        loss_key = f\"{step_name}_loss\"\n",
    "        tensorboard_logs = {loss_key: loss}\n",
    "\n",
    "        return { (\"loss\" if step_name == \"train\" else loss_key): loss, 'log': tensorboard_logs,\n",
    "               \"progress_bar\": {loss_key: loss}}\n",
    "\n",
    "    def forward(self, X, *args):\n",
    "        return self.model(X, *args)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"train\")\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"val\")\n",
    "\n",
    "    def validation_end(self, outputs: List[dict]):\n",
    "        loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        return {\"val_loss\": loss}\n",
    "        \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"test\")\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return self.create_data_loader(self.hparams.train_path, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.create_data_loader(self.hparams.val_path)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self.create_data_loader(self.hparams.test_path)\n",
    "                \n",
    "    def create_data_loader(self, ds_path: str, shuffle=False):\n",
    "        return DataLoader(\n",
    "                    EmoDataset(ds_path),\n",
    "                    batch_size=self.hparams.batch_size,\n",
    "                    shuffle=shuffle,\n",
    "                    collate_fn=TokenizersCollateFn()\n",
    "        )\n",
    "        \n",
    "    @lru_cache()\n",
    "    def total_steps(self):\n",
    "        return len(self.train_dataloader()) // self.hparams.accumulate_grad_batches * self.hparams.epochs\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        ## use AdamW optimizer -- faster approach to training NNs\n",
    "        ## read: https://www.fast.ai/2018/07/02/adam-weight-decay/\n",
    "        optimizer = AdamW(self.model.parameters(), lr=self.hparams.lr)\n",
    "        lr_scheduler = get_linear_schedule_with_warmup(\n",
    "                    optimizer,\n",
    "                    num_warmup_steps=self.hparams.warmup_steps,\n",
    "                    num_training_steps=self.total_steps(),\n",
    "        )\n",
    "        return [optimizer], [{\"scheduler\": lr_scheduler, \"interval\": \"step\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OGc7Vw1moHxr"
   },
   "source": [
    "## Finding Learning rate for the model\n",
    "\n",
    "The code below aims to obtain valuable information about the optimal learning rate during a pretraining run. Determine boundary and increase the leanring rate linearly or exponentially.\n",
    "\n",
    "More: https://github.com/davidtvs/pytorch-lr-finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QDHYc1m3Re46",
    "outputId": "6e46a167-d2ea-4d3a-ec92-5c2473dc8318"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_training.pkl  sample_data  tokenizer  val.txt\n",
      "pytorch-lr-finder    test.txt\t  train.txt\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ebxEBGDsRdzk",
    "outputId": "c427a70a-737f-4fb3-ab00-5359f1644e4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running install\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "writing torch_lr_finder.egg-info/PKG-INFO\n",
      "writing dependency_links to torch_lr_finder.egg-info/dependency_links.txt\n",
      "writing requirements to torch_lr_finder.egg-info/requires.txt\n",
      "writing top-level names to torch_lr_finder.egg-info/top_level.txt\n",
      "adding license file 'LICENSE'\n",
      "writing manifest file 'torch_lr_finder.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "running build_py\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/torch_lr_finder\n",
      "copying build/lib/torch_lr_finder/__init__.py -> build/bdist.linux-x86_64/egg/torch_lr_finder\n",
      "copying build/lib/torch_lr_finder/lr_finder.py -> build/bdist.linux-x86_64/egg/torch_lr_finder\n",
      "byte-compiling build/bdist.linux-x86_64/egg/torch_lr_finder/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/torch_lr_finder/lr_finder.py to lr_finder.cpython-37.pyc\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying torch_lr_finder.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying torch_lr_finder.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying torch_lr_finder.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying torch_lr_finder.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying torch_lr_finder.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "creating 'dist/torch_lr_finder-0.2.1-py3.7.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Processing torch_lr_finder-0.2.1-py3.7.egg\n",
      "Removing /usr/local/lib/python3.7/dist-packages/torch_lr_finder-0.2.1-py3.7.egg\n",
      "Copying torch_lr_finder-0.2.1-py3.7.egg to /usr/local/lib/python3.7/dist-packages\n",
      "torch-lr-finder 0.2.1 is already the active version in easy-install.pth\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/torch_lr_finder-0.2.1-py3.7.egg\n",
      "Processing dependencies for torch-lr-finder==0.2.1\n",
      "Searching for packaging==21.3\n",
      "Best match: packaging 21.3\n",
      "Adding packaging 21.3 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for tqdm==4.64.0\n",
      "Best match: tqdm 4.64.0\n",
      "Adding tqdm 4.64.0 to easy-install.pth file\n",
      "Installing tqdm script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for torch==1.11.0+cu113\n",
      "Best match: torch 1.11.0+cu113\n",
      "Adding torch 1.11.0+cu113 to easy-install.pth file\n",
      "Installing convert-caffe2-to-onnx script to /usr/local/bin\n",
      "Installing convert-onnx-to-caffe2 script to /usr/local/bin\n",
      "Installing torchrun script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for numpy==1.21.6\n",
      "Best match: numpy 1.21.6\n",
      "Adding numpy 1.21.6 to easy-install.pth file\n",
      "Installing f2py script to /usr/local/bin\n",
      "Installing f2py3 script to /usr/local/bin\n",
      "Installing f2py3.7 script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for matplotlib==3.2.2\n",
      "Best match: matplotlib 3.2.2\n",
      "Adding matplotlib 3.2.2 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for pyparsing==3.0.9\n",
      "Best match: pyparsing 3.0.9\n",
      "Adding pyparsing 3.0.9 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for typing-extensions==4.1.1\n",
      "Best match: typing-extensions 4.1.1\n",
      "Adding typing-extensions 4.1.1 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for python-dateutil==2.8.2\n",
      "Best match: python-dateutil 2.8.2\n",
      "Adding python-dateutil 2.8.2 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for kiwisolver==1.4.3\n",
      "Best match: kiwisolver 1.4.3\n",
      "Adding kiwisolver 1.4.3 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for cycler==0.11.0\n",
      "Best match: cycler 0.11.0\n",
      "Adding cycler 0.11.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for six==1.15.0\n",
      "Best match: six 1.15.0\n",
      "Adding six 1.15.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Finished processing dependencies for torch-lr-finder==0.2.1\n"
     ]
    }
   ],
   "source": [
    "!cd pytorch-lr-finder && python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yWfNe4HYRjih",
    "outputId": "827b39e3-ade3-4236-a7ec-028ffc5fee6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build\t\t examples  README.md  torch_lr_finder\n",
      "CONTRIBUTING.md  images    setup.py   torch_lr_finder.egg-info\n",
      "dist\t\t LICENSE   tests\n"
     ]
    }
   ],
   "source": [
    "!cd pytorch-lr-finder/ && ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Bw6EVCKmuXB"
   },
   "source": [
    "#### torch_lr_finder (below 3 blocks) has import error -> not working when i actually run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "NGY7wWy0Sf9_"
   },
   "outputs": [],
   "source": [
    "import torch_lr_finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "WcHs16mUSiYk"
   },
   "outputs": [],
   "source": [
    "from torch_lr_finder import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xL4lNPDFoFyU",
    "outputId": "47f6379b-f56e-4582-9dc0-dd2f54781d50"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/models/auto/modeling_auto.py:973: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "lr=0.1 ## uper bound LR\n",
    "#from torch_lr_finder import LRFinder\n",
    "hparams_tmp = Namespace(\n",
    "    train_path=train_path,\n",
    "    val_path=val_path,\n",
    "    test_path=test_path,\n",
    "    batch_size=16,\n",
    "    warmup_steps=100,\n",
    "    epochs=1,\n",
    "    lr=lr,\n",
    "    accumulate_grad_batches=1,\n",
    ")\n",
    "module = TrainingModule(hparams_tmp)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = AdamW(module.parameters(), lr=5e-7) ## lower bound LR\n",
    "# lr_finder = LRFinder(module, optimizer, criterion, device=\"cuda\")\n",
    "# lr_finder.range_test(module.train_dataloader(), end_lr=100, num_iter=100, accumulation_steps=hparams_tmp.accumulate_grad_batches)\n",
    "# lr_finder.plot()\n",
    "# lr_finder.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YdqP56M1oXav",
    "outputId": "04de20d8-5ddf-4812-f39e-4812c24a6a3c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 1e-4 \n",
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "vMab6vu0Bow0"
   },
   "outputs": [],
   "source": [
    "#lr_finder.plot(show_lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZhHutCseBxjJ"
   },
   "source": [
    "## Training the Emotion Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LxZwsOr_nITm"
   },
   "source": [
    "#### This is what we actually ended up running, don't be confused by the above codes which looked like the one here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q3FiLr3LBrjs",
    "outputId": "3e6573db-7ed3-4e25-b4a2-8a0fc1327760"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/models/auto/modeling_auto.py:973: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "hparams = Namespace(\n",
    "    train_path=train_path,\n",
    "    val_path=val_path,\n",
    "    test_path=test_path,\n",
    "    batch_size=32,\n",
    "    warmup_steps=100,\n",
    "    epochs=1,\n",
    "    lr=lr,\n",
    "    accumulate_grad_batches=1\n",
    ")\n",
    "module = TrainingModule(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "N8Jv_U25B37g"
   },
   "outputs": [],
   "source": [
    "## garbage collection\n",
    "import gc; gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 416,
     "referenced_widgets": [
      "087232ec10554d10b087fbeab4a8926a",
      "bc53cd79b41c4b52ba5f5797a91bc74a",
      "29a4489414e74aee8a1967a21293f3a1",
      "371be7fff66c4d25a5936a8d0af43205",
      "1ecc028f9ded41e59a0c4c0f3cb485d0",
      "2ec41dee2b044beeb2e58a2de8e842da",
      "9cd296586ffb4805a4a9078d0b05be7a",
      "692f98980f7c414d8eaae60e1c3dedaf",
      "5338b8ac50284509b1dbe7023c2db705",
      "8c33ffb5eb044e6383b961324a884f42",
      "30b721aeaa2845c29082267e9a3f6698",
      "bcb755ec248c412495f1145a564b9ed8",
      "1da6259ae04c4081838cd14f863798aa",
      "a3f2e4a3c78d4a8db51041183d20f330",
      "357b7ee1d18c449a8635989d65fb55eb",
      "4dc6b9b652f04d2b8f97aa417552bc34",
      "88fc7122035a4530aeb7a068c89b5825",
      "8c89b19daf6b45fca2885af91ec9c0c7",
      "4a683c26f7dc493893cf2198757e7c5e",
      "2967a62ffc7b40108895f0ac83254895",
      "5a5e508181784a97902d14a66841cc3e",
      "ebc02fcd15914abd87c7fdac35d69691",
      "4d868a8b588d4a8c8ad56ca004399482",
      "02578d884ca041d5a531b8c57a0d2c80",
      "5abcf1065e2b41ab8d94f934cab2ae4b",
      "5e1a1edcc7ad464aaa86f75aa512fcce",
      "aa49d597846849aaa97b5b9bf490675e",
      "f579ab188ef742c0b457caf87d9fc922",
      "19d383945ea548d3b24765cb4e45357d",
      "0bfad128e6824ea6910d6020fac5486b",
      "740aa1a2f04547159b4dcfbe06f795e8",
      "3e386f348cc8425bae0e8e1ac397dd4e",
      "a5df523790ae46bbac328eb6c52e526c"
     ]
    },
    "id": "oRnl4HXvB5-T",
    "outputId": "819579ef-3995-4a02-de32-18eaf945fa4f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/callback_connector.py:97: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=10)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  f\"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and\"\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: /content/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "\n",
      "  | Name  | Type             | Params\n",
      "-------------------------------------------\n",
      "0 | model | EmoModel         | 82.1 M\n",
      "1 | loss  | CrossEntropyLoss | 0     \n",
      "-------------------------------------------\n",
      "82.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "82.1 M    Total params\n",
      "328.492   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "087232ec10554d10b087fbeab4a8926a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcb755ec248c412495f1145a564b9ed8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d868a8b588d4a8c8ad56ca004399482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## train roughly for about 10-15 minutes with GPU enabled.\n",
    "trainer = pl.Trainer(gpus=1, max_epochs=hparams.epochs, progress_bar_refresh_rate=10,\n",
    "                     accumulate_grad_batches=hparams.accumulate_grad_batches)\n",
    "\n",
    "trainer.fit(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y8kzE1AeB_ij",
    "outputId": "1d1098c8-054f-4fd5-a3cd-c342c7d9813c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "________________________________________________________________________________\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     sadness   0.965458  0.962134  0.963793       581\n",
      "         joy   0.957101  0.930935  0.943837       695\n",
      "        love   0.787709  0.886792  0.834320       159\n",
      "       anger   0.902778  0.945455  0.923623       275\n",
      "        fear   0.893805  0.901786  0.897778       224\n",
      "    surprise   0.826923  0.651515  0.728814        66\n",
      "\n",
      "    accuracy                       0.926000      2000\n",
      "   macro avg   0.888962  0.879770  0.882027      2000\n",
      "weighted avg   0.927207  0.926000  0.925894      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    progress = [\"/\", \"-\", \"\\\\\", \"|\", \"/\", \"-\", \"\\\\\", \"|\"]\n",
    "    module.eval()\n",
    "    true_y, pred_y = [], []\n",
    "    for i, batch_ in enumerate(module.test_dataloader()):\n",
    "        (X, attn), y = batch_\n",
    "        #batch = (X.cuda(), attn.cuda()) # who put this stupid line here, which messed up the devices\n",
    "        batch = X, attn\n",
    "        print(progress[i % len(progress)], end=\"\\r\")\n",
    "        # but now it takes forever to calculate a single epoch\n",
    "        y_pred = torch.argmax(module(batch), dim=1)\n",
    "        true_y.extend(y.cpu())\n",
    "        pred_y.extend(y_pred.cpu())\n",
    "print(\"\\n\" + \"_\" * 80)\n",
    "print(classification_report(true_y, pred_y, target_names=label2int.keys(), digits=len(emotions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9G2nO4YqtRqI"
   },
   "source": [
    "### Let's actually save the result in a .txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "TPoV5pAItl_J",
    "outputId": "d40990ed-c800-476a-afcd-80a9fe417ac7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'drive/MyDrive/AI_sheng/emo_0.pt'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this would throw an error, we have to \"mount the drive\" first, see the cells below\n",
    "PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XzLr43hauJlR"
   },
   "source": [
    "### Always remember to change the newly saved file name to avoid over-writing the previous records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "yPU7bmVbsvqa"
   },
   "outputs": [],
   "source": [
    "with open(\"drive/MyDrive/AI_sheng/emo_0_result.txt\", \"w\") as f:\n",
    "  for line in classification_report(true_y, pred_y, target_names=label2int.keys(), digits=len(emotions)):\n",
    "    f.write(line)\n",
    "  f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U0_Z_4Pkl3fc",
    "outputId": "3baf7356-b590-4644-ba09-cfc80d49ec30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul  4 13:50:54 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   72C    P0    33W /  70W |   1428MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "ifER7sn-Htge",
    "outputId": "0fe775f6-7fba-4764-c6a5-e639221ab8e7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\nWhat we need is to save the trained model (weights &)\\n\\n\\nto save model:\\n  module.model (?) # see TrainingModule class\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "What we need is to save the trained model (weights &)\n",
    "\n",
    "\n",
    "to save model:\n",
    "  module.model (?) # see TrainingModule class\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KZL5wlwxY_Ev"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# to load the model, the class definition would not be saved in the file\n",
    "# and therefore should be recorded somewhere else\n",
    "PATH = ...\n",
    "torch.save(module.model.state_dict(), PATH)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8JqQTlytduK5"
   },
   "outputs": [],
   "source": [
    "# to verify if it works\n",
    "\"\"\"\n",
    "model = ...\n",
    "model.load(PATH)\n",
    "model.eval() # important to not change the params in the model\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4HuLuKX1hWf9",
    "outputId": "de5688c7-2a2b-46c1-904a-846fbd5a7c1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BbcK7A7ChXTH",
    "outputId": "5ed35c91-bca6-46e6-9524-922bf1a52a77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "「RoBERTa_Fine_Tuning_Emotion_classification.ipynb」的副本\n"
     ]
    }
   ],
   "source": [
    "!ls drive/MyDrive/AI_sheng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wqUUt5VWhj4k",
    "outputId": "c623dd17-154e-4c14-d9fb-8ac15f1ba402"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "base_model.embeddings.position_ids \t torch.Size([1, 514])\n",
      "base_model.embeddings.word_embeddings.weight \t torch.Size([50265, 768])\n",
      "base_model.embeddings.position_embeddings.weight \t torch.Size([514, 768])\n",
      "base_model.embeddings.token_type_embeddings.weight \t torch.Size([1, 768])\n",
      "base_model.embeddings.LayerNorm.weight \t torch.Size([768])\n",
      "base_model.embeddings.LayerNorm.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.0.attention.self.query.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.0.attention.self.query.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.0.attention.self.key.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.0.attention.self.key.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.0.attention.self.value.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.0.attention.self.value.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.0.attention.output.dense.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.0.attention.output.dense.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.0.attention.output.LayerNorm.weight \t torch.Size([768])\n",
      "base_model.encoder.layer.0.attention.output.LayerNorm.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.0.intermediate.dense.weight \t torch.Size([3072, 768])\n",
      "base_model.encoder.layer.0.intermediate.dense.bias \t torch.Size([3072])\n",
      "base_model.encoder.layer.0.output.dense.weight \t torch.Size([768, 3072])\n",
      "base_model.encoder.layer.0.output.dense.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.0.output.LayerNorm.weight \t torch.Size([768])\n",
      "base_model.encoder.layer.0.output.LayerNorm.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.1.attention.self.query.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.1.attention.self.query.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.1.attention.self.key.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.1.attention.self.key.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.1.attention.self.value.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.1.attention.self.value.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.1.attention.output.dense.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.1.attention.output.dense.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.1.attention.output.LayerNorm.weight \t torch.Size([768])\n",
      "base_model.encoder.layer.1.attention.output.LayerNorm.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.1.intermediate.dense.weight \t torch.Size([3072, 768])\n",
      "base_model.encoder.layer.1.intermediate.dense.bias \t torch.Size([3072])\n",
      "base_model.encoder.layer.1.output.dense.weight \t torch.Size([768, 3072])\n",
      "base_model.encoder.layer.1.output.dense.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.1.output.LayerNorm.weight \t torch.Size([768])\n",
      "base_model.encoder.layer.1.output.LayerNorm.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.2.attention.self.query.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.2.attention.self.query.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.2.attention.self.key.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.2.attention.self.key.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.2.attention.self.value.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.2.attention.self.value.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.2.attention.output.dense.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.2.attention.output.dense.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.2.attention.output.LayerNorm.weight \t torch.Size([768])\n",
      "base_model.encoder.layer.2.attention.output.LayerNorm.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.2.intermediate.dense.weight \t torch.Size([3072, 768])\n",
      "base_model.encoder.layer.2.intermediate.dense.bias \t torch.Size([3072])\n",
      "base_model.encoder.layer.2.output.dense.weight \t torch.Size([768, 3072])\n",
      "base_model.encoder.layer.2.output.dense.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.2.output.LayerNorm.weight \t torch.Size([768])\n",
      "base_model.encoder.layer.2.output.LayerNorm.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.3.attention.self.query.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.3.attention.self.query.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.3.attention.self.key.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.3.attention.self.key.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.3.attention.self.value.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.3.attention.self.value.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.3.attention.output.dense.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.3.attention.output.dense.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.3.attention.output.LayerNorm.weight \t torch.Size([768])\n",
      "base_model.encoder.layer.3.attention.output.LayerNorm.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.3.intermediate.dense.weight \t torch.Size([3072, 768])\n",
      "base_model.encoder.layer.3.intermediate.dense.bias \t torch.Size([3072])\n",
      "base_model.encoder.layer.3.output.dense.weight \t torch.Size([768, 3072])\n",
      "base_model.encoder.layer.3.output.dense.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.3.output.LayerNorm.weight \t torch.Size([768])\n",
      "base_model.encoder.layer.3.output.LayerNorm.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.4.attention.self.query.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.4.attention.self.query.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.4.attention.self.key.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.4.attention.self.key.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.4.attention.self.value.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.4.attention.self.value.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.4.attention.output.dense.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.4.attention.output.dense.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.4.attention.output.LayerNorm.weight \t torch.Size([768])\n",
      "base_model.encoder.layer.4.attention.output.LayerNorm.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.4.intermediate.dense.weight \t torch.Size([3072, 768])\n",
      "base_model.encoder.layer.4.intermediate.dense.bias \t torch.Size([3072])\n",
      "base_model.encoder.layer.4.output.dense.weight \t torch.Size([768, 3072])\n",
      "base_model.encoder.layer.4.output.dense.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.4.output.LayerNorm.weight \t torch.Size([768])\n",
      "base_model.encoder.layer.4.output.LayerNorm.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.5.attention.self.query.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.5.attention.self.query.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.5.attention.self.key.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.5.attention.self.key.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.5.attention.self.value.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.5.attention.self.value.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.5.attention.output.dense.weight \t torch.Size([768, 768])\n",
      "base_model.encoder.layer.5.attention.output.dense.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.5.attention.output.LayerNorm.weight \t torch.Size([768])\n",
      "base_model.encoder.layer.5.attention.output.LayerNorm.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.5.intermediate.dense.weight \t torch.Size([3072, 768])\n",
      "base_model.encoder.layer.5.intermediate.dense.bias \t torch.Size([3072])\n",
      "base_model.encoder.layer.5.output.dense.weight \t torch.Size([768, 3072])\n",
      "base_model.encoder.layer.5.output.dense.bias \t torch.Size([768])\n",
      "base_model.encoder.layer.5.output.LayerNorm.weight \t torch.Size([768])\n",
      "base_model.encoder.layer.5.output.LayerNorm.bias \t torch.Size([768])\n",
      "classifier.1.weight \t torch.Size([768, 768])\n",
      "classifier.1.bias \t torch.Size([768])\n",
      "classifier.4.weight \t torch.Size([6, 768])\n",
      "classifier.4.bias \t torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in module.model.state_dict():\n",
    "    print(param_tensor, \"\\t\", module.model.state_dict()[param_tensor].size())\n",
    "\n",
    "# # Print optimizer's state_dict\n",
    "# print(\"Optimizer's state_dict:\")\n",
    "# for var_name in optimizer.state_dict():\n",
    "#     print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "8kVoyK8EiB9X"
   },
   "outputs": [],
   "source": [
    "# save the whole damn thing, not just the weight, but the hyperparams, loss, etc\n",
    "# Additional information\n",
    "EPOCH = 1\n",
    "PATH = \"drive/MyDrive/AI_sheng/emo_0.pt\"\n",
    "LOSS = 0.\n",
    "\n",
    "torch.save({\n",
    "            'epoch': EPOCH,\n",
    "            'model_state_dict': module.model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': LOSS,\n",
    "            }, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6soIToaSmESp",
    "outputId": "ed7a386f-6ff9-49ca-c621-853224c644c0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/models/auto/modeling_auto.py:973: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EmoModel(\n",
       "  (base_model): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.05, inplace=False)\n",
       "    (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (2): Mish()\n",
       "    (3): Dropout(p=0.05, inplace=False)\n",
       "    (4): Linear(in_features=768, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test load model\n",
    "# we need the architecture\n",
    "model = EmoModel(AutoModelWithLMHead.from_pretrained(\"distilroberta-base\").base_model, len(emotions))\n",
    "optimizer = AdamW(model.parameters(), lr=0.0001)\n",
    "\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# epoch = checkpoint['epoch']\n",
    "# loss = checkpoint['loss']\n",
    "\n",
    "model.eval()\n",
    "# - or -\n",
    "# model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Hq2Mrijrq-i"
   },
   "source": [
    "### Save for inference only as well to reduce the file size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "gNawGPDjryW-",
    "outputId": "b5c6d436-d5f9-434c-8d51-a40c5aec1aba"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'drive/MyDrive/AI_sheng/emo_0.pt'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "K5KmeThkrvTe"
   },
   "outputs": [],
   "source": [
    "torch.save(module.model, 'drive/MyDrive/AI_sheng/emo_0_inference_only.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m6u0MkwUrAFg",
    "outputId": "e9906ed9-4353-40ad-8b02-2bce61b57808"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/models/auto/modeling_auto.py:973: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EmoModel(\n",
       "  (base_model): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.05, inplace=False)\n",
       "    (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (2): Mish()\n",
       "    (3): Dropout(p=0.05, inplace=False)\n",
       "    (4): Linear(in_features=768, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test load model\n",
    "# we need the architecture\n",
    "model = EmoModel(AutoModelWithLMHead.from_pretrained(\"distilroberta-base\").base_model, len(emotions))\n",
    "optimizer = AdamW(model.parameters(), lr=0.0001)\n",
    "\n",
    "checkpoint = torch.load(\"drive/MyDrive/AI_sheng/emo_0.pt\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# epoch = checkpoint['epoch']\n",
    "# loss = checkpoint['loss']\n",
    "\n",
    "model.eval()\n",
    "# - or -\n",
    "# model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "coa5eqiduyaV",
    "outputId": "e231d930-b71c-4e34-93f7-d38173426cb5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[   0,  118,  376,  ...,    1,    1,    1],\n",
       "         [   0,  118,   21,  ...,    1,    1,    1],\n",
       "         [   0,  757, 2157,  ...,    1,    1,    1],\n",
       "         ...,\n",
       "         [   0,  118,  619,  ...,    1,    1,    1],\n",
       "         [   0,  757, 2157,  ...,    1,    1,    1],\n",
       "         [   0,  118,  619,  ...,    1,    1,    1]]),\n",
       " tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# previously used test batch to test if the reloaded model works\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6-4byblHuobq",
    "outputId": "274754a3-b52d-4db1-f330-9b582627b498"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9080, -1.2302, -0.9013,  5.8108, -0.3313, -1.6975],\n",
       "        [-2.0946,  6.4397,  0.3476, -1.8304, -1.9126, -1.6221],\n",
       "        [-1.0167, -1.4537, -2.5131, -0.5782,  6.0331, -0.0138],\n",
       "        [ 6.1555, -0.9121, -1.5822,  0.0782, -0.4525, -1.8345],\n",
       "        [ 6.1081, -0.0588, -1.4681, -0.5297, -0.9191, -1.9302],\n",
       "        [ 5.9176, -0.2496, -0.8827,  0.4110, -1.6411, -2.4032],\n",
       "        [-1.5229,  2.6171,  4.4723, -2.0810, -2.4527, -2.6025],\n",
       "        [-1.4750,  2.2911,  4.3958, -1.4681, -2.4978, -2.7022],\n",
       "        [-2.1249, -1.7336, -1.9561,  2.9887,  2.9735,  0.1342],\n",
       "        [-0.8134, -1.6481, -1.5137,  5.8931,  0.3576, -1.3272],\n",
       "        [ 5.9923, -1.1148, -1.9877, -0.3512,  0.3510, -1.4085],\n",
       "        [ 1.0029,  0.2793,  1.0631,  3.3292, -2.5348, -2.9683],\n",
       "        [-0.6613, -1.4232, -1.0356,  5.8153, -0.2930, -1.5194],\n",
       "        [-1.8507,  6.3146, -0.0732, -1.9502, -2.2076, -0.7117],\n",
       "        [-1.8714,  6.5112,  0.0234, -2.0143, -1.5364, -1.5565],\n",
       "        [-1.5251, -0.9851, -2.0907, -1.8387,  3.6508,  3.0799]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model reload works (inference only works)\n",
    "model.forward(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below codes are newly added for exporting & api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's just start from here and export the passed codes\n",
    "#### don't train the whole model unless it's necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting this won't work\n",
    "# since they're locally imported\n",
    "def setup_imports():\n",
    "    \"\"\"\n",
    "    import everything is slow, try to fix it after we nailed down the data classes\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    from torch import nn\n",
    "    from typing import List\n",
    "    import torch.nn.functional as F\n",
    "    from transformers import DistilBertTokenizer, AutoTokenizer, AutoModelWithLMHead, DistilBertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "    import logging\n",
    "    import os\n",
    "    from functools import lru_cache\n",
    "    from tokenizers import ByteLevelBPETokenizer\n",
    "    from tokenizers.processors import BertProcessing\n",
    "    import pytorch_lightning as pl\n",
    "    from torch.utils.data import DataLoader, Dataset\n",
    "    import pandas as pd\n",
    "    from argparse import Namespace\n",
    "    from sklearn.metrics import classification_report\n",
    "    print(torch.__version__)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "# necessary evil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# from https://github.com/digantamisra98/Mish/blob/b5f006660ac0b4c46e2c6958ad0301d7f9c59651/Mish/Torch/mish.py\n",
    "@torch.jit.script\n",
    "def mish(input):\n",
    "    return input * torch.tanh(F.softplus(input))\n",
    "\n",
    "class Mish(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return mish(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class EmoModel(nn.Module):\n",
    "    def __init__(self, base_model, n_classes, base_model_output_size=768, dropout=0.05):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(base_model_output_size, base_model_output_size),\n",
    "            Mish(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(base_model_output_size, n_classes)\n",
    "        )\n",
    "\n",
    "        for layer in self.classifier:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                layer.weight.data.normal_(mean=0.0, std=0.02)\n",
    "                if layer.bias is not None:\n",
    "                    layer.bias.data.zero_()\n",
    "\n",
    "    def forward(self, input_, *args):\n",
    "        X, attention_mask = input_\n",
    "        hidden_states = self.base_model(X, attention_mask=attention_mask)\n",
    "        # customize here\n",
    "        # use the <s> representation\n",
    "        return self.classifier(hidden_states[0][:, 0, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### write the label2int map since it's used everywhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "label2int = {\n",
    "    \"sadness\": 0,\n",
    "    \"joy\": 1,\n",
    "    \"love\": 2,\n",
    "    \"anger\": 3,\n",
    "    \"fear\": 4,\n",
    "    \"surprise\": 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KXyDjO6zuqGS"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def get_model(PATH, pretrained=True, inference_only=True, lr=0.0001):\n",
    "    if PATH[-3:] != \".pt\" and PATH[-4:] != \".pth\":\n",
    "        print(\"Unable to load pretrained model\")\n",
    "        return None\n",
    "\n",
    "    # show warning message when it's inference only but lr has been changed\n",
    "    if inference_only == True and lr != 0.0001:\n",
    "        print(\"Warning: the loaded model is for inference only, so there's no optimizer for the changed learning rate\")\n",
    "    # model = EmoModel(AutoModelWithLMHead.from_pretrained(\"distilroberta-base\").base_model, len(emotions))\n",
    "    # see above cell: emotions = [\"sadness\", \"joy\", \"love\", \"anger\", \"fear\", \"surprise\"]\n",
    "    # len(label2int) would work as well\n",
    "    from transformers import AutoModelWithLMHead\n",
    "    model = EmoModel(AutoModelWithLMHead.from_pretrained(\"distilroberta-base\").base_model, 6)\n",
    "\n",
    "    # if you want to re-train the head\n",
    "    if pretrained == False:\n",
    "        return model\n",
    "\n",
    "    checkpoint = torch.load(PATH)\n",
    "\n",
    "    if inference_only:\n",
    "        # model would not be subscriptable\n",
    "        model.load_state_dict(checkpoint)\n",
    "        model.eval()\n",
    "    else:\n",
    "        # lr: learning rate, adjustable\n",
    "        from transformers import AdamW\n",
    "        optimizer = AdamW(model.parameters(), lr=lr)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        model.train()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For inference only, we should just take advantage of the class TokenizersCollateFN() class defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# save the pretrained token\n",
    "def load_tokenizer():\n",
    "    from tokenizers import AutoTokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained('distilroberta-base')\n",
    "    # -p, --parent, no error if it exists, make parent directory as necessary\n",
    "    os.system(\"mkdir -p tokenizer\")\n",
    "    tokenizer.save_pretrained(\"tokenizer\")\n",
    "\n",
    "def setup_tokenizer():\n",
    "    # if there's no previous file/record\n",
    "    # should we check if there are missing files given that it's previously downloaded?\n",
    "    if not os.path.isdir(\"tokenizer\"):\n",
    "        load_tokenizer()\n",
    "\n",
    "    else: # content of previously download files is not complete\n",
    "        checklist = ['merges.txt', 'special_tokens_map.json', 'tokenizer.json', 'tokenizer_config.json', 'vocab.json']\n",
    "        # check existing files\n",
    "        # existing_files = os.walk(os.path.join(os.getcwd(), \"tokenizer\"))\n",
    "        existing_files = list(os.walk(\"tokenizer\"))[0][2]\n",
    "        # os.walk() won't messed up the order of the searched files,\n",
    "        # so, we can just use \"==\" operator\n",
    "        if existing_files != checklist:\n",
    "            # clean the previously download ones\n",
    "            os.system(\"rmdir -rf tokenizer\")\n",
    "            # and, re-download it\n",
    "            load_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def print_emotion(output):\n",
    "    # output = model.forward(input)\n",
    "    idx = torch.argmax(output, dim=1)\n",
    "    from EMO_AI.model_api import label2int\n",
    "    for key in label2int:\n",
    "        if label2int[key] == idx:\n",
    "            print(\"Emotion: %s\" % key)\n",
    "            break\n",
    "    return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def call_model(text, model_path, inference_only=True):\n",
    "    model = get_model(model_path, inference_only=inference_only)\n",
    "    from EMO_AI.data_process import get_tokenizer\n",
    "    get_tokenizer()\n",
    "    output = model.forward(convert_text_to_tensor(text))\n",
    "    return output"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "jKRrSAEnojUe",
    "E3W9Ps2aUFA-",
    "_whSBDujRiga",
    "9RFifOoY7Hsc",
    "wjgME-3O8Yfo",
    "I-N7WSY7Cb7v",
    "4hu70Ng0Eqls",
    "-FJ-wN1_zmkV",
    "rJm31gKShQus",
    "rAD1J6c0dLp8",
    "0h6tTn9hd6v8",
    "OGc7Vw1moHxr",
    "2Bw6EVCKmuXB"
   ],
   "name": "「RoBERTa_Fine_Tuning_Emotion_classification.ipynb」的副本",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.7.9 ('AI_sheng')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "9db77c7d38baf4b93e998a2213b9026a3d1545f748ab5419893b25caa4e3cb58"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02578d884ca041d5a531b8c57a0d2c80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f579ab188ef742c0b457caf87d9fc922",
      "placeholder": "​",
      "style": "IPY_MODEL_19d383945ea548d3b24765cb4e45357d",
      "value": "Validation DataLoader 0: 100%"
     }
    },
    "087232ec10554d10b087fbeab4a8926a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bc53cd79b41c4b52ba5f5797a91bc74a",
       "IPY_MODEL_29a4489414e74aee8a1967a21293f3a1",
       "IPY_MODEL_371be7fff66c4d25a5936a8d0af43205"
      ],
      "layout": "IPY_MODEL_1ecc028f9ded41e59a0c4c0f3cb485d0"
     }
    },
    "0a24cf351cd6416b96998cf2f5da2512": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b3a93724ad3d4fd48a5471af0f0400af",
      "placeholder": "​",
      "style": "IPY_MODEL_62c6c07e96e649df8c22514a8689009e",
      "value": "Downloading: 100%"
     }
    },
    "0a889fbe6d58487cb250e18c1e4e9907": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3c4d2966c20b41f891bf4d2786ad9bce",
       "IPY_MODEL_fc3bdaecaaf34c2a87dbf888c7d6276f",
       "IPY_MODEL_18f13adddb904b72a713555453af20f4"
      ],
      "layout": "IPY_MODEL_3c6d2d4247de4426ab952770d58fe11a"
     }
    },
    "0bfad128e6824ea6910d6020fac5486b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d7c6e994a7e4b6aba2a475ced08c87c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "18f13adddb904b72a713555453af20f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f68bc923635046b09f8f864f90221b79",
      "placeholder": "​",
      "style": "IPY_MODEL_8b2a46ebb9f74408898e120289efe571",
      "value": " 446k/446k [00:00&lt;00:00, 10.1kB/s]"
     }
    },
    "19d383945ea548d3b24765cb4e45357d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1da6259ae04c4081838cd14f863798aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_88fc7122035a4530aeb7a068c89b5825",
      "placeholder": "​",
      "style": "IPY_MODEL_8c89b19daf6b45fca2885af91ec9c0c7",
      "value": "Epoch 0: 100%"
     }
    },
    "1dd352a1a5764185b3070bec03b1eed1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e26029c0b394dc0a8e2aa24eb3b563d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1dd352a1a5764185b3070bec03b1eed1",
      "placeholder": "​",
      "style": "IPY_MODEL_226e92a0d27f407784a84cff66fdd5bb",
      "value": "Downloading: 100%"
     }
    },
    "1ecc028f9ded41e59a0c4c0f3cb485d0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "226e92a0d27f407784a84cff66fdd5bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "27d620c696774566a9147b6543631cdc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2967a62ffc7b40108895f0ac83254895": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "29a4489414e74aee8a1967a21293f3a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_692f98980f7c414d8eaae60e1c3dedaf",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5338b8ac50284509b1dbe7023c2db705",
      "value": 2
     }
    },
    "2ac61322048848d19ceae50bd23e783a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d2e210040cba466590a57f14dc463deb",
      "placeholder": "​",
      "style": "IPY_MODEL_346aa2f0c3324c8a8ea3e54370b6004a",
      "value": "Downloading: 100%"
     }
    },
    "2ec41dee2b044beeb2e58a2de8e842da": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30b721aeaa2845c29082267e9a3f6698": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "346aa2f0c3324c8a8ea3e54370b6004a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "357b7ee1d18c449a8635989d65fb55eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a5e508181784a97902d14a66841cc3e",
      "placeholder": "​",
      "style": "IPY_MODEL_ebc02fcd15914abd87c7fdac35d69691",
      "value": " 563/563 [12:43&lt;00:00,  1.36s/it, loss=0.185, v_num=0]"
     }
    },
    "371be7fff66c4d25a5936a8d0af43205": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8c33ffb5eb044e6383b961324a884f42",
      "placeholder": "​",
      "style": "IPY_MODEL_30b721aeaa2845c29082267e9a3f6698",
      "value": " 2/2 [00:01&lt;00:00,  1.87it/s]"
     }
    },
    "3c4d2966c20b41f891bf4d2786ad9bce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0d7c6e994a7e4b6aba2a475ced08c87c",
      "placeholder": "​",
      "style": "IPY_MODEL_489efd83a5324299afed67e7c8cd642f",
      "value": "Downloading: 100%"
     }
    },
    "3c6d2d4247de4426ab952770d58fe11a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3e386f348cc8425bae0e8e1ac397dd4e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "419c3cb65daa4068894430fe02a0fdbf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1e26029c0b394dc0a8e2aa24eb3b563d",
       "IPY_MODEL_7ac1ef8a96ca4ffa98b84c0146b05b3a",
       "IPY_MODEL_e1fd29ec64d844cf8a336e8dc4b56d16"
      ],
      "layout": "IPY_MODEL_c4f2a52e0bea43b7abdba2e4fda1e046"
     }
    },
    "47452bb290fb462da0444aa57585f840": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "489efd83a5324299afed67e7c8cd642f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4a683c26f7dc493893cf2198757e7c5e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d868a8b588d4a8c8ad56ca004399482": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_02578d884ca041d5a531b8c57a0d2c80",
       "IPY_MODEL_5abcf1065e2b41ab8d94f934cab2ae4b",
       "IPY_MODEL_5e1a1edcc7ad464aaa86f75aa512fcce"
      ],
      "layout": "IPY_MODEL_aa49d597846849aaa97b5b9bf490675e"
     }
    },
    "4dc6b9b652f04d2b8f97aa417552bc34": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "4f784f40b2c6470e9b4663448333e308": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "50f4185d84c442858bc270dccd3f0190": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5338b8ac50284509b1dbe7023c2db705": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "55aa8b496bdb4e2c89037ed3a9416c33": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a5e508181784a97902d14a66841cc3e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5abcf1065e2b41ab8d94f934cab2ae4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0bfad128e6824ea6910d6020fac5486b",
      "max": 63,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_740aa1a2f04547159b4dcfbe06f795e8",
      "value": 63
     }
    },
    "5e1a1edcc7ad464aaa86f75aa512fcce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3e386f348cc8425bae0e8e1ac397dd4e",
      "placeholder": "​",
      "style": "IPY_MODEL_a5df523790ae46bbac328eb6c52e526c",
      "value": " 63/63 [00:30&lt;00:00,  2.08it/s]"
     }
    },
    "5ee53b7b6fc34e2dbc8d0fe3346af00c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "62c6c07e96e649df8c22514a8689009e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "692f98980f7c414d8eaae60e1c3dedaf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "699dd771419c4f1392b9725aec5f4c9e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "711ce4c4c7ea47e8a374f710e4d0e59a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "740aa1a2f04547159b4dcfbe06f795e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "74eb6e5637ee4611b6f4b9a2a14e620e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0a24cf351cd6416b96998cf2f5da2512",
       "IPY_MODEL_c4ce1e4457d6438093cc83dc1f3f143f",
       "IPY_MODEL_cb473ac8713d4066b8fd7aa03a1c429d"
      ],
      "layout": "IPY_MODEL_7bbb1627a28640549737062b3d979a6c"
     }
    },
    "7ac1ef8a96ca4ffa98b84c0146b05b3a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e6a7e7cbc424407c9f59ab2afa2a4a8e",
      "max": 480,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9198556f3251499094563166fde76b11",
      "value": 480
     }
    },
    "7bbb1627a28640549737062b3d979a6c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "88fc7122035a4530aeb7a068c89b5825": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "89698711961f415d8891362453273919": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2ac61322048848d19ceae50bd23e783a",
       "IPY_MODEL_e8623d85e14741f0be0f41edcbde2fde",
       "IPY_MODEL_f8f5ff97a69442039ad481db4cc9dcb8"
      ],
      "layout": "IPY_MODEL_fdb737a550b7446ab61b85ad0e7d15e9"
     }
    },
    "8b2a46ebb9f74408898e120289efe571": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8c33ffb5eb044e6383b961324a884f42": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8c89b19daf6b45fca2885af91ec9c0c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9198556f3251499094563166fde76b11": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9a17f0749f4c4b71937971309023ed7b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9cd296586ffb4805a4a9078d0b05be7a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a3f2e4a3c78d4a8db51041183d20f330": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4a683c26f7dc493893cf2198757e7c5e",
      "max": 563,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2967a62ffc7b40108895f0ac83254895",
      "value": 563
     }
    },
    "a5df523790ae46bbac328eb6c52e526c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aa49d597846849aaa97b5b9bf490675e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "abf15a0b598f4fb18112d2311b62eeb2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b7c5e2f903b143da9638be238dd734ff",
      "placeholder": "​",
      "style": "IPY_MODEL_ceabcaf7af35477f92c419af41e78e40",
      "value": "Downloading: 100%"
     }
    },
    "ac6568c65a774f57b4c05d1f05147434": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b3a93724ad3d4fd48a5471af0f0400af": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b6eabc4f212d494aaf611d6b17d8b1b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_abf15a0b598f4fb18112d2311b62eeb2",
       "IPY_MODEL_d19f9c4760a540e9a263bdfac7dcf38c",
       "IPY_MODEL_eb36d0c9c3d246b49b43548261fa6390"
      ],
      "layout": "IPY_MODEL_9a17f0749f4c4b71937971309023ed7b"
     }
    },
    "b7c5e2f903b143da9638be238dd734ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc53cd79b41c4b52ba5f5797a91bc74a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2ec41dee2b044beeb2e58a2de8e842da",
      "placeholder": "​",
      "style": "IPY_MODEL_9cd296586ffb4805a4a9078d0b05be7a",
      "value": "Sanity Checking DataLoader 0: 100%"
     }
    },
    "bcb755ec248c412495f1145a564b9ed8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1da6259ae04c4081838cd14f863798aa",
       "IPY_MODEL_a3f2e4a3c78d4a8db51041183d20f330",
       "IPY_MODEL_357b7ee1d18c449a8635989d65fb55eb"
      ],
      "layout": "IPY_MODEL_4dc6b9b652f04d2b8f97aa417552bc34"
     }
    },
    "c4ce1e4457d6438093cc83dc1f3f143f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_55aa8b496bdb4e2c89037ed3a9416c33",
      "max": 331070498,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_711ce4c4c7ea47e8a374f710e4d0e59a",
      "value": 331070498
     }
    },
    "c4f2a52e0bea43b7abdba2e4fda1e046": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c8ea6b01fbf54f78b2707802b9f7807b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb473ac8713d4066b8fd7aa03a1c429d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_47452bb290fb462da0444aa57585f840",
      "placeholder": "​",
      "style": "IPY_MODEL_27d620c696774566a9147b6543631cdc",
      "value": " 316M/316M [00:10&lt;00:00, 30.5MB/s]"
     }
    },
    "ceabcaf7af35477f92c419af41e78e40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cebed77f95584d1884bb16d961651913": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d19f9c4760a540e9a263bdfac7dcf38c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4f784f40b2c6470e9b4663448333e308",
      "max": 1355863,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e5dbc0014c2047f688d05b07cd814abc",
      "value": 1355863
     }
    },
    "d2e210040cba466590a57f14dc463deb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de9a0fd1bd2b4af792c6786b9bf29e33": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e1fd29ec64d844cf8a336e8dc4b56d16": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f505b2bc24cb4c1ca73d41ea317be6a6",
      "placeholder": "​",
      "style": "IPY_MODEL_ac6568c65a774f57b4c05d1f05147434",
      "value": " 480/480 [00:00&lt;00:00, 3.72kB/s]"
     }
    },
    "e5a82d4b2b8a4b25a55650979a822eb8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e5d7192438aa4097aa75f0dcf000bacb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e5dbc0014c2047f688d05b07cd814abc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e6a7e7cbc424407c9f59ab2afa2a4a8e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e8623d85e14741f0be0f41edcbde2fde": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e5d7192438aa4097aa75f0dcf000bacb",
      "max": 898823,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5ee53b7b6fc34e2dbc8d0fe3346af00c",
      "value": 898823
     }
    },
    "eb36d0c9c3d246b49b43548261fa6390": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_699dd771419c4f1392b9725aec5f4c9e",
      "placeholder": "​",
      "style": "IPY_MODEL_de9a0fd1bd2b4af792c6786b9bf29e33",
      "value": " 1.29M/1.29M [00:00&lt;00:00, 9.23kB/s]"
     }
    },
    "ebc02fcd15914abd87c7fdac35d69691": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f505b2bc24cb4c1ca73d41ea317be6a6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f579ab188ef742c0b457caf87d9fc922": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f68bc923635046b09f8f864f90221b79": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f8f5ff97a69442039ad481db4cc9dcb8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c8ea6b01fbf54f78b2707802b9f7807b",
      "placeholder": "​",
      "style": "IPY_MODEL_50f4185d84c442858bc270dccd3f0190",
      "value": " 878k/878k [00:00&lt;00:00, 369kB/s]"
     }
    },
    "fc3bdaecaaf34c2a87dbf888c7d6276f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cebed77f95584d1884bb16d961651913",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e5a82d4b2b8a4b25a55650979a822eb8",
      "value": 456318
     }
    },
    "fdb737a550b7446ab61b85ad0e7d15e9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
